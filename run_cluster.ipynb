{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: RJ Ramey <rj.github@garimeme.com>\n",
      "# License: (c) 2014 by RJ Ramey. All rights reserved. \n",
      "# No license is given at this time.\n",
      "#\n",
      "# Does: * Chooses rows to fillna or drop\n",
      "#       * Normalizes each feature\n",
      "#       * Runs K-Means on several parameters to minimize Silhouette score\n",
      "#       * output: Comps_class.csv \n",
      "#       * output: histograms of features before/after normalization\n",
      "#       * output: 2x2 scatterplot of clusters on various M axes\n",
      "\n",
      "# Initialization\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.metrics import pairwise_distances\n",
      "try:  # Load table to df\n",
      "    df = pd.read_csv(\"data/cleaned/Final.csv\", header=0, index_col=0)\n",
      "    print \"Final.csv has %d rows, %d columns\" % (df.shape[0] , df.shape[1])  \n",
      "except IOError:\n",
      "    print \"WARNING: Missing required file /data/cleaned/Final.csv. Run feature_engineer first.\"\n",
      "\n",
      "# convenient references\n",
      "M28 = df.columns[df.columns.map(lambda x: x[0:3]=='M28')]\n",
      "M24 = df.columns[df.columns.map(lambda x: x[0:3]=='M24')]    \n",
      "\n",
      "#if allow_geolocation=True:  #if using Geolocated countries\n",
      "if True:\n",
      "    if len(df.columns[df.columns.map(lambda x: x[0:3]=='M28')]) > 0:\n",
      "        print \"Dataframe does contain measured countries from IP address:\"\n",
      "        countries = []  \n",
      "        for M in df.columns.values.tolist():  #make a quick list of M28_countries\n",
      "            if str(M)[0:3] == 'M28':\n",
      "                countries.append(str(M)[4:6])\n",
      "        countries = countries[1:]\n",
      "        print \"  \", countries\n",
      "    else:\n",
      "        print \"Data does not contain measured countries, so ignoring argument allow_geolocation.\"\n",
      "else:\n",
      "    df = df.drop(M28,axis=1)\n",
      "    df = df.drop(['M25'],axis=1)\n",
      "    \n",
      "print \"Working dataframe has %d rows, %d columns\" % (df.shape[0] , df.shape[1])    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Final.csv has 366 rows, 64 columns\n",
        "Dataframe does contain measured countries from IP address:\n",
        "   ['AU', 'CA', 'CN', 'DE', 'ES', 'FR', 'GB', 'IN', 'NL', 'RU', 'TW', 'US']\n",
        "Working dataframe has 366 rows, 64 columns\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TODO:  Get a new pull of QueryResults1790 !"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Preparation for SKLearn\n",
      "\n",
      "# Make assumptions to constrain Null and errant values\n",
      "\n",
      "# Nulls in X27: \n",
      "# convert concept of 'unlimited' to 10   #TODO: is this a good value\n",
      "print \"For %d competitions with unlimited-sized teams, assume max 10 (as practical reality)\" % len(df.X27[pd.isnull(df.X27) == True])\n",
      "df['X27_IsClamped'] = np.nan\n",
      "df.X27_IsClamped[pd.isnull(df.X27) == True] = 1\n",
      "df.X27[pd.isnull(df.X27) == True] = 10\n",
      "\n",
      "# If going to use M28: drop rows where M25 = 0, (would mean 'participants are from 0 countries')\n",
      "#if allow_geolocation=True:  #if using Geolocated countries\n",
      "if True:\n",
      "    if len(M28) > 0:\n",
      "        subseries = M28.append(np.array(['M25']))\n",
      "        # TODO: hack: save the one case where M28_countries do exist (a QueryResults mismatch)\n",
      "        df.M25[ (df.M25 == 0) & (df.M28_RU > 0) ] = 1\n",
      "        # Drop all other rows where M25 is 0\n",
      "        df = df[ (df.M25 <> 0) ]\n",
      "        # Fill in rest of null M28_countries as 0\n",
      "        df[subseries] = df[subseries].fillna(value=0)\n",
      "\n",
      "#...\n",
      "\n",
      "\n",
      "\n",
      "print df.shape\n",
      "#df = df.dropna(axis=0,how='any',thresh=12,inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Impute rows where [M24_3, M24_7, M24_15, M24_30, M24_deadline] < 0 or Null\n",
      "    # weird cases where there are many users on teams, but almost no RulesAccepters\n",
      "    # use Median for similarly Teams-Users sized?\n",
      "\n",
      "df[M24][ (pd.isnull(df.M24_3) == True) | (pd.isnull(df.M24_7) == True) | (pd.isnull(df.M24_15) == True) |  \n",
      "        (pd.isnull(df.M24_30) == True) | (pd.isnull(df.M24_deadline) == True)].head(4)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>M24_3</th>\n",
        "      <th>M24_7</th>\n",
        "      <th>M24_15</th>\n",
        "      <th>M24_30</th>\n",
        "      <th>M24_deadline</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2408</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0.166667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2435</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.711111</td>\n",
        "      <td> 0.590106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2438</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2442</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>4 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "      M24_3  M24_7  M24_15    M24_30  M24_deadline\n",
        "Id                                                \n",
        "2408    NaN    NaN     NaN       NaN      0.166667\n",
        "2435    NaN    NaN     NaN  0.711111      0.590106\n",
        "2438    NaN    NaN     NaN       NaN           NaN\n",
        "2442    NaN    NaN     NaN       NaN           NaN\n",
        "\n",
        "[4 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To Normalize\n",
      "final_compids = np.unique(df.index.values)\n",
      "\n",
      "DurationInt\n",
      "PrepDays\n",
      "DayOfYear\n",
      "DayOfWeek\n",
      "\n",
      "M10_3\tM10_7\tM10_15\tM10_30\tM10_deadline\tM12\n",
      "M8\n",
      "M25 \n",
      "\n",
      "M15\n",
      "M18_deadline\n",
      "\n",
      "X14\n",
      "X15\n",
      "X25\n",
      "X26 (or drop it)\n",
      "X27\n",
      "X31\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate figure3 for histograms\n",
      "def histograms(suffix, fignum, fields, binns):\n",
      "    \"\"\" Plots 4x2 figure of 8 columns which are passed, using bins as passed\"\"\"\n",
      "    fig = plt.figure(num=fignum, figsize=(18,18))\n",
      "    fig.suptitle('Histograms of ' + str(suffix) + ' features', fontsize=18)\n",
      "    ax1 = fig.add_subplot(421, axisbg='0.94')\n",
      "    ax2 = fig.add_subplot(422, axisbg='0.94')\n",
      "    ax3 = fig.add_subplot(423, axisbg='0.94')\n",
      "    ax4 = fig.add_subplot(424, axisbg='0.94')\n",
      "    ax5 = fig.add_subplot(425, axisbg='0.94')\n",
      "    ax6 = fig.add_subplot(426, axisbg='0.94')\n",
      "    ax7 = fig.add_subplot(427, axisbg='0.94')\n",
      "    ax8 = fig.add_subplot(428, axisbg='0.94')\n",
      "    alphas = [0.33, 0.33, 0.6, 0.6, 0.28, 0.28, 0.6, 0.6]\n",
      "    hues = ['g','b','b','g','g','b','b','g']\n",
      "    all_axes = plt.gcf().axes\n",
      "    for i, ax in list(enumerate(all_axes)):\n",
      "        ax.set_ylabel(\"count\", fontsize=10)\n",
      "        for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
      "            ticklabel.set_fontsize(14)\n",
      "        if (len(fields) - 1) >= i:\n",
      "            try:\n",
      "                #range_of_1_std = df[fields[i]].std() + df[fields[i]].mean()\n",
      "                ax.hist(df[fields[i]].dropna().values, bins=binns[i], color=hues[i],alpha=alphas[i])  #, range=(0,range_of_1_std)\n",
      "                ax.set_title(df[fields[i]].name, fontsize=20)\n",
      "            except:\n",
      "                print \"WARNING: An error occurred in composing Figure %d\" % fignum\n",
      "                return\n",
      "    try:  # Save the figure as one file\n",
      "        filename = \"data/vis/histogram\" + \"_\" + str(fignum) + \"_\" + str(suffix) + \".png\"\n",
      "        plt.savefig(filename)\n",
      "        print \"=  Vis Output: \", filename\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: \", filename\n",
      "        print\n",
      "    plt.close(fig)\n",
      "\n",
      "        \n",
      "histograms('raw', 1, ['DayOfYear','DayOfWeek', 'M15', 'M18_deadline' ], [10,7,12,12])\n",
      "\n",
      "if True:  #if allow_geolocation=True:\n",
      "    histograms('raw', 26, ['M10_3','M10_7','M10_15','M10_30','M10_deadline','M8','M12','M25'], [12,12,12,12,12,12,12,12])\n",
      "else:\n",
      "    histograms('raw', 26, ['M10_3','M10_7','M10_15','M10_30','M10_deadline','M8','M12'], [12,12,12,12,12,12,12])\n",
      " \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "=  Vis Output:  data/vis/histogram_1_raw.png\n",
        "=  Vis Output: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " data/vis/histogram_26_raw.png\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# K-Means clustering\n",
      "def run_kmeans_4(km, data):\n",
      "    km.fit(data)\n",
      "    centroids = km.cluster_centers_\n",
      "    print \"centroids:\", centroids\n",
      "    labels = km.labels_\n",
      "    metrics.silhouette_score(X, labels, metric='euclidean')\n",
      "    \n",
      "    y = km.predict(data)\n",
      "    \n",
      "    \n",
      "    fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
      "    # t below must match the number of clusters in km\n",
      "    for t,marker,c in zip(xrange(4),\">ox+\",\"rgby\") :\n",
      "        ax.scatter(data[y == t,0],\n",
      "                   data[y == t,1],\n",
      "                   marker=marker,\n",
      "                   c=c)\n",
      "\n",
      "    ax.scatter(centroids[:,0],centroids[:,1],marker = 's',c='r')\n",
      "\n",
      "\n",
      "\n",
      "# km = KMeans(n_clusters=4, init='random', n_init=1, max_iter=1, random_state=1)\n",
      "km = KMeans(n_clusters=4, init='k-means++', n_init=10 , max_iter = 300, random_state=1)\n",
      "\n",
      "run_kmeans_4(km, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate the Silhouette score for different values of k\n",
      "for k in xrange(2,8):\n",
      "    km = KMeans(n_clusters=k, random_state=1)\n",
      "    km.fit(X)\n",
      "    labels = km.labels_\n",
      "    print k, metrics.silhouette_score(X, labels, metric='euclidean')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Recap of measurements\n",
      "#'-M' indicates features which are dropped\n",
      "\n",
      "####M1.\tDuration in days  = from data_cleaner, 'DurationInt'\n",
      "####M2.\tDayofYear launchdate (seasonal behavior)  = from data_cleaner, 'DayOfYear'\n",
      "####M3.\tDayOfWeek of launchdate  (weekend behavior)  = from data_cleaner, 'DayOfWeek'\n",
      "###\n",
      "#### -M4.\tCount of valid-submitting Users globally on Kaggle as of Launch, Deadline  \n",
      "#### M6.\tCount of forum topics in 3d, 7d, 15d, 30d, deadline  # TODO: later\n",
      "###\n",
      "#### -M7.\tCount of forum messages in 3d, 7d, 15d, 30d\n",
      "#### M8.\tCount of forum messages at deadline\n",
      "#### M9.\tRatio of [M7]/[M8]   (relative early forum activity)\n",
      "#### M10.\tAvg length of forum messages in 3d, 7d, 15d, 30d  (14-day trailing average)\n",
      "###\n",
      "#### -M11.\tCount of valid submissions in 3d, 7d, 15d, 30d    (QueryResults1810-1814 concat)\n",
      "#### M12.\tCount of valid submissions at deadline            (QueryResults1810-1814 concat)\n",
      "#### M13.\tRatio of [M11]/[M12]  (relative early subm activity) \n",
      "###\n",
      "#### -M14.\tCount of users on teams in 3d, 7d, 15d, 30d   (QueryResults1815)\n",
      "#### M15.\tCount of users on teams at Deadline           (QueryResults1815)\n",
      "#### M16.  Ratio of [M14]/[M15]  (relative early user entry)\n",
      "#### -M43.\tCount of [M15] where User profile contains a bio|LinkedIn|twitter|Github (QueryResults1816)\n",
      "#### M44.\tRatio of 1 - [M43]/[M15]  (user anonymity rate)  (QueryResults1816)\n",
      "###\n",
      "#### -M17.\tCount of multiplayer teams at deadline\n",
      "#### M18.\tCount of teams in 3d, 7d, 15d, 30d  (QueryResults1807)\n",
      "#### M18_deadline. Count of teams at deadline  (QueryResults1807)\n",
      "#### M19.  Ratio of [M17]/[M18]  (Proportion of multiplayer teams) \n",
      "#### M20.  Ratio of [M18]/[M18_deadline]  (relative early team appearance )\n",
      "#### -M21.\tCount of RulesAcceptance in 3d, 7d, 15d, 30d, deadline (lurkers vs players)\n",
      "###\n",
      "#### M22.\tRatio of [M14]/[M4]  (participation relative to all possible participation)\n",
      "#### M23.\tRatio of [M21]/[M4]  (interest relative to all possible participation)\n",
      "#### M24.\t(1 - [M14]/[M21])   (relative lurker rate)\n",
      "###\n",
      "#### M25.\tCount of countries represented by participants (geographic diversity)\n",
      "#### -M26.\tCount of users on teams at deadline in Major countries  (QueryResults1808)\n",
      "#### -M27.  Count of universe of users in Major countries at deadline (QueryResults1560)\n",
      "#### M28.  Ratio of [M26]/[M27]  (relative popularity in each major country)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}