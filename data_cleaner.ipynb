{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Outline of future code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The complete project should contain a series of scripts that start from these inputs:\n",
      "#     * csv from internal SQL query results  (confidential - can't put on Github)\n",
      "# \n",
      "# A. And produces a series of outputs:\n",
      "#   * clean/coded csv's (on Github)\n",
      "#   * Feature engineering  (20-45 derived measurements)\n",
      "#     * output: measurement csvs to ./data/cleaned/  (ok on Github)\n",
      "#     * plot:   histograms to ./data/vis/  (ok on Github)\n",
      "#   * Feature normalization:\n",
      "#     * output:  normalized measurement csv's (on Github)\n",
      "#\n",
      "# B. Assembles outputs:\n",
      "#   * JOIN ON competitionId to each normalized measurement table\n",
      "#\n",
      "# C. Unsupervised analysis:\n",
      "#   * (?) Performs PCA analysis\n",
      "#   * KMeans clustering\n",
      "#\n",
      "# D. Visualizer\n",
      "#\n",
      "# E. Analytical write-up  (confidential - present to instructors & Kaggle team)\n",
      "\n",
      "\n",
      "# Part A\n",
      "\n",
      "# Data_cleaner:\n",
      "#    1. ingest data/raw/Competitions csv\n",
      "#       1. rename columns to X1, X2, X3 etc.\n",
      "#       2. drop unneeded columns\n",
      "#    2. OUTPUT:  data/clean/competitions_clean.csv\n",
      "#    3. Munge data (missing values)\n",
      "#    4. Repeat 1-3 for all other tables\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Class data_cleaner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: RJ Ramey <rj.github@garimeme.com>\n",
      "# License: (c) 2014 by RJ Ramey. All rights reserved. No license is given at this time."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setup and Initialization\n",
      "from datetime import datetime\n",
      "from time import time\n",
      "import os.path\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IO / data load\n",
      "\n",
      "def modification_date(filename):\n",
      "    \"\"\" return the modified date from a filename \"\"\"\n",
      "    t = os.path.getmtime(filename)\n",
      "    return datetime.fromtimestamp(t)\n",
      "\n",
      "def printhelp():\n",
      "    \"\"\" prints expected inputs to the console \"\"\"\n",
      "    \n",
      "    print \"== INPUTS ==\"\n",
      "    print \"data_cleaner expects certain confidential files in /data/raw/\"\n",
      "    print \"  QueryResults1784.csv\"\n",
      "    print \"  QueryResults1790.csv\"\n",
      "##  ...\n",
      "    print\n",
      "    print \"Trailing digits xxxx indicate the output of a SQL Explorer query found at https://sql.kaggle.com/kaggle/xxxx/\"\n",
      "\n",
      "# Load Competitions table\n",
      "try:\n",
      "    df_Competitions = pd.read_csv(\"data/raw/QueryResults1784.csv\",header=0,index_col=0)\n",
      "    print \"==== Cleaning QueryResults1784.csv ====\"\n",
      "except IOError:\n",
      "    print \"Missing input: data/raw/QueryResults1784.csv\"\n",
      "    print\n",
      "    printhelp()\n",
      "\n",
      "# Code the feature names for public storage on Github\n",
      "print \"Masking feature names from raw data ...\"\n",
      "t00 = time()\n",
      "coded_names = [ 'X' + str(i) for i in range (1, len(df_Competitions.columns) + 1)]\n",
      "        # save the dictionary for future reversal, will return this value from function\n",
      "coded_legend = { code: orig for code, orig in (zip(coded_names, df_Competitions.columns))}\n",
      "\n",
      "df_Competitions.columns = coded_names\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Data Munging\n",
      "\n",
      "# Convert X17 {3: 3, all others : 1}\n",
      "print \"Flatten feature X17 to values {1,3} ...\"\n",
      "df_Competitions.loc[ df_Competitions.X17 <> 3, 'X17' ] = 1 \n",
      "\n",
      "# Create future JOIN table of foreign keys\n",
      "print \"Saving future JOIN table : /data/cleaned/foreignkeys.csv ...\"\n",
      "df_ForeignKeys = df_Competitions[['X10','X12','X13','X16','X17','X18','X22','X23']]\n",
      "df_ForeignKeys.to_csv('./data/cleaned/foreignkeys.csv') \n",
      "\n",
      "print \"Force column type of boolean and date fields ...\"\n",
      "  # Convert X23 to bool, {null: 0, notnull: 1}\n",
      "df_Competitions['Is_X23'] = df_Competitions.X23.map(lambda x: x/x)       # evaluates to 1\n",
      "df_Competitions.loc[ df_Competitions.Is_X23.isnull(), 'Is_X23' ] = 0   # sets remaining 0\n",
      "coded_legend['Is_X23'] = str('Is' + coded_legend['X23'][0:20])\n",
      "\n",
      "  # Convert boolean columns to 1/0\n",
      "for cn in list(df_Competitions.columns[df_Competitions.dtypes.map(lambda x: x=='bool')]):\n",
      "    df_Competitions[cn] = df_Competitions[cn].astype(int)\n",
      "\n",
      "  # Convert text dates to UTC datetimes\n",
      "df_Competitions['X5'] = pd.to_datetime(df_Competitions.X5, utc=True)   \n",
      "df_Competitions['X6'] = pd.to_datetime(df_Competitions.X6, utc=True)   \n",
      "df_Competitions['X7'] = pd.to_datetime(df_Competitions.X7, utc=True)   \n",
      "df_Competitions['X8'] = pd.to_datetime(df_Competitions.X8, utc=True)   \n",
      "df_Competitions['X19'] = pd.to_datetime(df_Competitions.X19, utc=True)    \n",
      "\n",
      "print \"Checking for valid dates :\"\n",
      "t0 = time()\n",
      "\n",
      "  # Check where X5 is missing; assume it to = X6\n",
      "flags = 0\n",
      "flags = len(df_Competitions[ df_Competitions.X5.isnull() == True])\n",
      "if flags > 0:\n",
      "    print \"    INFO: filling %d missing dates ...\" % flags\n",
      "    df_Competitions.loc[ (df_Competitions.X5.isnull() == True), 'X5' ] = df_Competitions.X6\n",
      "\n",
      "  # Check where dates should be previous in time to the subsequent one; force it so\n",
      "flags = 0\n",
      "flags = len(df_Competitions[ df_Competitions.X6 > df_Competitions.X7])\n",
      "if flags > 0:\n",
      "    print \"    INFO: found %d questionable dates relative to Launch. Making assumptions ...\" % flags\n",
      "    df_Competitions.loc[ (df_Competitions.X6 > df_Competitions.X7), 'X6' ] = df_Competitions.X7\n",
      "    \n",
      "flags = 0\n",
      "flags = len(df_Competitions[ (df_Competitions.X6.isnull() == False) & (df_Competitions.X5 > df_Competitions.X6)])\n",
      "if flags > 0:\n",
      "    print \"    INFO: found %d more questionable dates. Making assumptions ...\" % flags\n",
      "    \n",
      "    # calculate to find value of X5 that are off by almost exactly 1 year\n",
      "    df_Competitions['X5_X6'] = pd.to_timedelta( \n",
      "                                              (df_Competitions.X5 - df_Competitions.X6),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "    \n",
      "    # if seems close to 1 year off, assume human error, and subtract 1 year\n",
      "    if len(df_Competitions[ (df_Competitions.X5_X6 > 300) & (df_Competitions.X5_X6 < 367) ]) > 0:\n",
      "        df_Competitions.loc[ (df_Competitions.X5_X6 > 300) & (df_Competitions.X5_X6 < 367) , 'X5' ] = pd.to_datetime(df_Competitions.X5) - np.timedelta64(366,'D')\n",
      "        \n",
      "    # but if not almost exactly 1 year, then just force to same as X6\n",
      "    if len(df_Competitions[df_Competitions.X5_X6 >= 367]) > 0:\n",
      "        df_Competitions.loc[ (df_Competitions.X5_X6 >= 367), 'X5' ] = df_Competitions.X6\n",
      "    if len(df_Competitions[ (df_Competitions.X5_X6 > 0) & (df_Competitions.X5_X6 <= 300) ]) > 0:\n",
      "        df_Competitions.loc[ (df_Competitions.X5_X6 > 0) & (df_Competitions.X5_X6 <= 300), 'X5' ] = df_Competitions.X6\n",
      "    \n",
      "    # remove the temporary calculation column\n",
      "    df_Competitions = df_Competitions.drop(['X5_X6'], axis=1)\n",
      "\n",
      "duration = time() - t0\n",
      "print \"    ...done in %fs\" % duration\n",
      "\n",
      "\n",
      "# Additional feature engineering\n",
      "# do date arithmetic, converts to ns, calculate back to days\n",
      "origindate = datetime(2010, 1, 1)\n",
      "analysisdate = modification_date(\"data/raw/QueryResults1784.csv\")\n",
      "analysisdate64 = np.datetime64(analysisdate)\n",
      "todaynow64 = np.datetime64(datetime.utcnow())\n",
      "print\n",
      "print \"Today is \", np.datetime_as_string(todaynow64)[0:10]\n",
      "print \"QueryResults seem to be from\", np.datetime_as_string(analysisdate64)[0:10]\n",
      "print\n",
      "print \"Creating new time measurements from datestamps ...\"\n",
      "\n",
      "t0 = time()\n",
      "df_Competitions['LaunchDaySeq'] = np.round(pd.to_timedelta( \n",
      "                                              (df_Competitions.X7 - origindate),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000)\n",
      "df_Competitions['Day3'] = df_Competitions.LaunchDaySeq + 3\n",
      "df_Competitions['Day7'] = df_Competitions.LaunchDaySeq + 7\n",
      "df_Competitions['Day14'] = df_Competitions.LaunchDaySeq + 14\n",
      "df_Competitions['Day30'] = df_Competitions.LaunchDaySeq + 30\n",
      "\n",
      "df_Competitions['DeadlineDaySeq'] = np.round(pd.to_timedelta( \n",
      "                                              (df_Competitions.X8 - origindate),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000)\n",
      "\n",
      "df_Competitions['InstructorPrepDays'] = pd.to_timedelta( \n",
      "                                              (df_Competitions.X6 - df_Competitions.X5),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "\n",
      "df_Competitions['PrepDays'] = pd.to_timedelta( \n",
      "                                              (df_Competitions.X7 - df_Competitions.X5),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "\n",
      "df_Competitions['DurationDays'] = pd.to_timedelta( \n",
      "                                              (df_Competitions.X8 - df_Competitions.X7),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "\n",
      "df_Competitions['DurationInt'] = (df_Competitions.DeadlineDaySeq - df_Competitions.LaunchDaySeq)\n",
      "\n",
      "df_Competitions['DayOfYear'] = pd.to_datetime(df_Competitions.X7.values).dayofyear\n",
      "df_Competitions['DayOfWeek'] = pd.to_datetime(df_Competitions.X7.values).dayofweek + 1   # Monday = 1, Sunday = 7\n",
      "\n",
      "df_Competitions['Postprocess_sec'] = pd.to_timedelta( \n",
      "                                              (df_Competitions.X19 - df_Competitions.X8),\n",
      "                                              unit='D').astype(np.timedelta64) / 1000000000\n",
      "\n",
      "df_Competitions['AgeInDays'] = pd.to_timedelta( \n",
      "                                              (analysisdate64 - df_Competitions.X7),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "\n",
      "df_Competitions['RemainingDays'] = pd.to_timedelta( \n",
      "                                              (analysisdate64 - df_Competitions.X8),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000\n",
      "duration = time() - t0\n",
      "print \"...done in %fs\" % duration\n",
      "\n",
      "# Delete all rows where comp is too young to analyze\n",
      "\n",
      "#   To use, a comp needs to be >30 days old, ergo Today - X7 > 30d\n",
      "#   and need to be < 30 days out to the final Deadline, ergo Today - X8 > -30\n",
      "print \"Dropping competitions that are too young to analyze ...\"\n",
      "df_Competitions = df_Competitions[ ((df_Competitions.AgeInDays > 30) & (df_Competitions.RemainingDays > -30))]\n",
      "\n",
      "# Drop rows for strange data (these dont seem to be real comps)\n",
      "df_Competitions = df_Competitions[df_Competitions.index <> 2553]\n",
      "df_Competitions = df_Competitions[df_Competitions.index <> 2554]\n",
      "df_Competitions = df_Competitions[df_Competitions.index <> 3867]\n",
      "df_Competitions = df_Competitions[df_Competitions.DurationDays > 1.5]\n",
      "\n",
      "\n",
      "unique_comps = np.unique(df_Competitions.index.values)\n",
      "print \"%d competitions are remaining for analysis\" % len(unique_comps)\n",
      "\n",
      "# Drop unneeded columns\n",
      "df_Competitions = df_Competitions.drop(['X10','X12','X13','X16','X17','X18','X22','X23'], axis=1)   # Drop the foreign key columns\n",
      "df_Competitions = df_Competitions.drop(['X2','X3','X4'], axis=1)                                    # Drop descriptive (text) columns\n",
      "df_Competitions = df_Competitions.drop(['X19'], axis=1)                     # Drop unneeded date column (now measured in Postprocess_ms)\n",
      "df_Competitions = df_Competitions.drop(['AgeInDays'], axis=1)\n",
      "df_Competitions = df_Competitions.drop(['RemainingDays'], axis=1)\n",
      "\n",
      "\n",
      "# !!!!!  TEMP   !!!!!!\n",
      "# for now, store a many-column version\n",
      "print\n",
      "try:\n",
      "    df_Competitions.to_csv('./data/cleaned/comps_full.csv') \n",
      "    print \"= (Temp output : /data/cleaned/comps_full.csv)\"\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/cleaned/comps_full.csv\"\n",
      "    print\n",
      "\n",
      "\n",
      "t0 = time()\n",
      "# Visualizations for exploration\n",
      "# Instantiate figure 0 for histograms\n",
      "fig = plt.figure(num=0, figsize=(15,22))\n",
      "fig.suptitle('Histograms of new features', fontsize=14)\n",
      "ax1 = fig.add_subplot(4,1,1)\n",
      "ax2 = fig.add_subplot(4,1,2)\n",
      "ax3 = fig.add_subplot(4,1,3)\n",
      "ax4 = fig.add_subplot(4,1,4)\n",
      "\n",
      "all_axes = plt.gcf().axes\n",
      "for ax in all_axes:\n",
      "    ax.set_ylabel(\"count\", fontsize=10)\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
      "        ticklabel.set_fontsize(10)\n",
      "\n",
      "#hist 1\n",
      "range_of_1_std = df_Competitions.DurationInt.std() + df_Competitions.DurationInt.mean()\n",
      "ax1.hist(df_Competitions.DurationInt.values, bins=25, range=(0,range_of_1_std), color='r',alpha=0.5)\n",
      "ax1.set_xlabel(\"(days)\", fontsize=10)\n",
      "ax1.set_title('DurationInt [deadline - launched]', fontsize=12)\n",
      "#hist 2\n",
      "range_of_1_std = df_Competitions.PrepDays.std() + df_Competitions.PrepDays.mean()\n",
      "ax2.hist(df_Competitions.PrepDays.values, bins=25, range=(0,range_of_1_std), color='b',alpha=0.5)\n",
      "ax2.set_xlabel(\"(days)\", fontsize=10)\n",
      "ax2.set_title('PrepDays [launched - created]', fontsize=12)\n",
      "#hist 3\n",
      "range_of_1_std = df_Competitions.InstructorPrepDays.std() + df_Competitions.InstructorPrepDays.mean()\n",
      "ax3.hist(df_Competitions.InstructorPrepDays.values, bins=25, range=(0,range_of_1_std), color='b',alpha=0.25)\n",
      "ax3.set_xlabel(\"(days)\", fontsize=10)\n",
      "ax3.set_title('InstructorPrepDays [submitted - created]', fontsize=12)\n",
      "#hist 4\n",
      "range_of_1_std = df_Competitions.Postprocess_sec.std() + df_Competitions.Postprocess_sec.mean()\n",
      "ax4.hist(df_Competitions.Postprocess_sec.values, bins=25, range=(0,range_of_1_std), color='g',alpha=0.8)\n",
      "ax4.set_xlabel(\"(sec)\", fontsize=10)\n",
      "ax4.set_title('private leaderboard Postprocess_sec', fontsize=12)\n",
      "\n",
      "# Save the figure as one file\n",
      "try:\n",
      "    plt.savefig('./data/vis/features1_histograms.png')\n",
      "    duration = time() - t0\n",
      "    print \"=  Output vis : /data/vis/features1_histograms.png\"\n",
      "    print \"    done in %fs\" % duration\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/vis/features1_histograms.png\"\n",
      "    print\n",
      "\n",
      "t0 = time()\n",
      "# Instantiate figure 1 for boxplots\n",
      "fig = plt.figure(num=1, figsize=(15,8))\n",
      "fig.suptitle('Outliers in Preparation days', fontsize=14)\n",
      "ax1 = fig.add_subplot(1,3,1)\n",
      "ax2 = fig.add_subplot(1,3,2)\n",
      "ax3 = fig.add_subplot(1,3,3)\n",
      "all_axes = plt.gcf().axes\n",
      "for ax in all_axes:\n",
      "    ax.set_ylabel(\"days\", fontsize=10)\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
      "        ticklabel.set_fontsize(10)\n",
      "\n",
      "#boxplot 1\n",
      "ax2.boxplot(df_Competitions.PrepDays.values, sym='go')\n",
      "ax2.set_title('PrepDays [launched - created]', fontsize=12)\n",
      "#boxplot 2\n",
      "ax3.boxplot(df_Competitions.InstructorPrepDays.values, sym='bo')\n",
      "ax3.set_title('InstructorPrepDays [submitted - created]', fontsize=12)\n",
      "#boxplot 3\n",
      "ax1.boxplot(df_Competitions.DurationInt.values, sym='ro')\n",
      "ax1.set_title('DurationInt [deadline - launched]', fontsize=12)\n",
      "\n",
      "# Save the figure as one file\n",
      "try:\n",
      "    plt.savefig('./data/vis/features1_outliers.png')\n",
      "    duration = time() - t0\n",
      "    print \"=  Output vis : /data/vis/features1_outliers.png\"\n",
      "    print \"    done in %fs\" % duration\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/vis/features1_outliers.png\"\n",
      "    print\n",
      "\n",
      "\n",
      "# Drop remaining columns no longer needed\n",
      "df_Competitions = df_Competitions.drop(['X1','X5','X6','X7','X8','X9','X28','X29'], axis=1)\n",
      "df_Competitions = df_Competitions.drop(['Postprocess_sec'], axis=1)    # this proved to not vary significantly, not useful\n",
      "# ... more to come? ...\n",
      "\n",
      "\n",
      "# Write to /cleaned folder\n",
      "print\n",
      "try:\n",
      "    df_Competitions.to_csv('./data/cleaned/comps.csv') \n",
      "    print \"=  Clean output : /data/cleaned/comps.csv\"\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/cleaned/comps.csv\"\n",
      "    print\n",
      "\n",
      "# Reclaim memory\n",
      "df_Competitions = []\n",
      "duration = time() - t00\n",
      "print \"File done in %fs\" % duration\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==== Cleaning QueryResults1784.csv ====\n",
        "Masking feature names from raw data ...\n",
        "Flatten feature X17 to values {1,3} ...\n",
        "Saving future JOIN table : /data/cleaned/foreignkeys.csv ...\n",
        "Force column type of boolean and date fields ...\n",
        "Checking for valid dates :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    INFO: filling 54 missing dates ...\n",
        "    INFO: found 5 questionable dates relative to Launch. Making assumptions ...\n",
        "    INFO: found 8 more questionable dates. Making assumptions ...\n",
        "    ...done in 0.033630s\n",
        "\n",
        "Today is  2014-05-05\n",
        "QueryResults seem to be from 2014-05-01\n",
        "\n",
        "Creating new time measurements from datestamps ...\n",
        "...done in 0.043222s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Dropping competitions that are too young to analyze ...\n",
        "359 competitions are remaining for analysis\n",
        "\n",
        "= (Temp output : /data/cleaned/comps_full.csv)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "=  Output vis : /data/vis/features1_histograms.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    done in 1.972940s\n",
        "=  Output vis : /data/vis/features1_outliers.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    done in 0.716069s\n",
        "\n",
        "=  Clean output : /data/cleaned/comps.csv\n",
        "File done in 3.158415s\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# Load RuleAccepters table\n",
      "try:\n",
      "    df_RuleAccepters = pd.read_csv(\"data/raw/QueryResults1790.csv\",header=0)\n",
      "    print\n",
      "    print \"==== Cleaning QueryResults1790.csv ====\"\n",
      "except IOError:\n",
      "    print \"Missing input: data/raw/QueryResults1790.csv\"\n",
      "    print\n",
      "    printhelp()\n",
      "\n",
      "t00 = time()\n",
      "# Data Munging\n",
      "  # Convert text dates to UTC datetimes\n",
      "df_RuleAccepters['LogDate'] = pd.to_datetime(df_RuleAccepters.LogDate, utc=True) \n",
      "  # Convert dates to sequential day from 1/1/2010\n",
      "df_RuleAccepters['DaySeq'] = np.round(pd.to_timedelta( \n",
      "                                              (df_RuleAccepters.LogDate - origindate),\n",
      "                                              unit='D').astype(np.timedelta64) / 86400 / 1000000000)\n",
      "  # remove null CompetitionIds\n",
      "df_RuleAccepters = df_RuleAccepters[ df_RuleAccepters.CompetitionId.isnull() == False ]\n",
      "\n",
      "print \"Contains data for %d competitions\" % len(np.unique(df_RuleAccepters.CompetitionId))\n",
      "print \"Constraining to %d competitions under analysis\" % len(unique_comps)\n",
      "\n",
      "print \"Calculating cumulative total of Accepters per day ...\"\n",
      "\n",
      "t0 = time()\n",
      "cumul_array = np.empty([3,],dtype=float)\n",
      "for c in unique_comps:\n",
      "    operate = df_RuleAccepters.iloc[:,[1,3,2]][ (df_RuleAccepters.CompetitionId == c) ].set_index('DaySeq')\n",
      "    cumul = 0\n",
      "    for i in operate.index:\n",
      "        cumul = cumul + operate.xs(i,axis=0,copy=False)['RuleAccepted']\n",
      "        cumul_array = np.vstack([cumul_array, [ c, i, cumul ]])\n",
      "duration = time() - t0\n",
      "print \"...done in %fs\" % duration\n",
      "\n",
      "cumul_array = cumul_array[1:]  # delete first row artifact from creating an np.empty\n",
      "\n",
      "try:\n",
      "    pd.DataFrame(data=cumul_array, columns=['CompetitionId','DaySeq','CumulAccepted']).to_csv('./data/cleaned/rules_accepters.csv') \n",
      "    print\n",
      "    print \"=  Clean output : /data/cleaned/rules_accepters.csv\"\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/cleaned/rules_accepters.csv\"\n",
      "    print\n",
      "\n",
      "# Reclaim memory\n",
      "cumul_array = np.empty([3,])\n",
      "operate = []\n",
      "df_RuleAccepters = []\n",
      "\n",
      "duration = time() - t00\n",
      "print \"File done in %fs\" % duration"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==== Cleaning QueryResults1790.csv ====\n",
        "Contains data for 439 competitions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Constraining to 359 competitions under analysis\n",
        "Calculating cumulative total of Accepters per day ...\n",
        "...done in 11.276718s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "=  Clean output : /data/cleaned/rules_accepters.csv\n",
        "File done in 11.827179s\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}