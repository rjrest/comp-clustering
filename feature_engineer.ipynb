{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Class feature_engineer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: RJ Ramey <rj.github@garimeme.com>\n",
      "# License: (c) 2014 by RJ Ramey. All rights reserved. \n",
      "# No license is given at this time.\n",
      "#\n",
      "# Does:   Feature engineering  (28 derived measurements)\n",
      "#         * output: measurement csvs to ./data/cleaned/M*.csv  (ok on Github)\n",
      "#         * plot:   histograms to ./data/vis/M*.png            (ok on Github)\n",
      "\n",
      "\n",
      "# Setup and Initialization\n",
      "from datetime import datetime\n",
      "from time import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "#from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
      "\n",
      "t000 = time()\n",
      "origindate = datetime(2010, 1, 1)\n",
      "M_legend = {}\n",
      "\n",
      "# Create measurements\n",
      "\n",
      "# Competitions table is global; will be used throughout\n",
      "try:\n",
      "    df_Competitions = pd.read_csv(\"data/cleaned/comps.csv\", \n",
      "                                          header=0, \n",
      "                                          usecols=[0,14,15,16,17,18,19,20,24], \n",
      "                                          index_col=0)\n",
      "    master_compids = np.unique(df_Competitions.index.values)\n",
      "except IOError:\n",
      "    print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "\n",
      "# Create features, priority A\n",
      "\n",
      "# M1.\tDuration in days \n",
      "#       = from data_cleaner, 'DurationInt'\n",
      "M_legend['DurationInt'] = 'Duration in days'\n",
      "\n",
      "# M2.\tDayofYear launchdate (seasonal behavior) \n",
      "#       = from data_cleaner, 'DayOfYear'\n",
      "M_legend['DayOfYear'] = 'Day of calendar year in range (1,366)'\n",
      "\n",
      "# M3.\tDayOfWeek of launchdate  (weekend behavior)  \n",
      "#       = from data_cleaner, 'DayOfWeek'\n",
      "M_legend['DayOfWeek'] = 'Day of week in range (1 Mon, 7 Sun)'\n",
      "\n",
      "# M4.\tCount of valid-submitting Users globally on Kaggle as of Launch, Deadline  \n",
      "def engineerM4():\n",
      "    \"\"\" Counts the number of Users (globally on the site) who have made a valid submission by that date in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M4.csv:  table with columns CompId, M4_launch, M4_3, M4_7, M4_15, M4_30, M4_deadline \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_SubmUsersGlobal = pd.read_csv(\"data/cleaned/users_globally.csv\",header=0,usecols=[1,2],index_col=0)\n",
      "        print\n",
      "        print \"Taking measurements from users_globally.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day0','Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '0', '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a total that day from the Query\n",
      "                getvalue = df_SubmUsersGlobal.loc[getdayseq]['CumulUsers'] \n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back                \n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 1\n",
      "                else:\n",
      "                    attempts = 32\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_SubmUsersGlobal.loc[getdayseq - i]['CumulUsers']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                # This can only occur if the day sought precedes any Global Users in history, so assume a value of 0\n",
      "                # Except that will cause a division by 0, so assume 1 Global User\n",
      "                if i == attempts:\n",
      "                    getvalue = 1\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty                      \n",
      "                    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M4_launch','M4_3','M4_7','M4_15','M4_30','M4_deadline']).to_csv('./data/cleaned/M4.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M4.csv\"\n",
      "        M_legend['M4_n'] = 'Count of universe of all possible users (ever made a valid submission) by day n'        \n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M4.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([8,])\n",
      "    collectrow = []\n",
      "    df_SubmUsersGlobal = []\n",
      "\n",
      "# M6.\tCount of forum topics in 3d, 7d, 15d, 30d, deadline\n",
      "# TODO: later\n",
      "\n",
      "# M7.\tCount of forum messages in 3d, 7d, 15d, 30d\n",
      "# M8.\tCount of forum messages at deadline\n",
      "# M9.\tRatio of [M7]/[M8]   (relative early forum activity)\n",
      "def engineerM7_M8_M9():\n",
      "    \"\"\" Counts the number of Forum messages posted in the competition by that date in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M7_M8_M9.csv:  table with measurements M7, M8 and M9 \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_ForumMg = pd.read_csv(\"data/cleaned/forum_msg.csv\",header=0)\n",
      "        df_ForumMg.rename(columns={'0':'CountMsg'}, inplace=True)\n",
      "        df_ForumMg.sort(['Id','DaySeq'], ascending=[1, 1], inplace=True, axis=0)\n",
      "        print\n",
      "        print \"Taking measurements from forum_msg.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    print \"Contains data for %d competitions,\" % len(np.unique(df_ForumMg.Id))\n",
      "    print \"   constraining to %d competitions under analysis\" % len(master_compids)\n",
      "    print \"   Calculating cumulative total of Forum messages per day ...\"\n",
      "    \n",
      "    t0 = time()\n",
      "    cumul_array = np.empty([3,],dtype=float)\n",
      "    for c in master_compids:\n",
      "        operate = df_ForumMg.iloc[:][ (df_ForumMg.Id == c) ].set_index('DaySeq')\n",
      "        cumul = 0\n",
      "        for i in operate.index.values:\n",
      "            cumul = cumul + operate.xs(i,axis=0,copy=False)['CountMsg']\n",
      "            cumul_array = np.vstack([cumul_array, [ c, i, cumul ]])\n",
      "    duration = time() - t0\n",
      "    print \"   ::done in %fs\" % duration\n",
      "    \n",
      "    cumul_array = cumul_array[1:]  # delete first row artifact from creating an np.empty\n",
      "                                   # the iterable data is now in a np.array 'cumul_array'\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq)][0,2]   #get first result in 3rd column\n",
      "                getvalue = np.float(getvalue)\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 1\n",
      "                else:\n",
      "                    attempts = 31\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        \n",
      "                        getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq - i)][0,2]\n",
      "                        getvalue = np.float(getvalue)\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                        \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now it is known there were 0 forum entries\n",
      "                if i == attempts:\n",
      "                    getvalue = 0\n",
      "\n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "\n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M7_3','M7_7','M7_15','M7_30','M8'])\n",
      "    # initialize new columns for M9\n",
      "    df_results['M9_3'] = np.nan\n",
      "    df_results['M9_7'] = np.nan\n",
      "    df_results['M9_15'] = np.nan\n",
      "    df_results['M9_30'] = np.nan\n",
      "    # calculate M9 (relative early forum activity)\n",
      "    df_results.M9_3[df_results.M8 <> 0] = df_results.M7_3 / df_results.M8\n",
      "    df_results.M9_7[df_results.M8 <> 0] = df_results.M7_7 / df_results.M8\n",
      "    df_results.M9_15[df_results.M8 <> 0] = df_results.M7_15 / df_results.M8\n",
      "    df_results.M9_30[df_results.M8 <> 0] = df_results.M7_30 / df_results.M8\n",
      "    # If a competition never had any forum messages, set all proportions to 100%\n",
      "    df_results.M9_3[df_results.M8 == 0] = 1\n",
      "    df_results.M9_7[df_results.M8 == 0] = 1\n",
      "    df_results.M9_15[df_results.M8 == 0] = 1\n",
      "    df_results.M9_30[df_results.M8 == 0] = 1\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M7_M8_M9.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M7_M8_M9.csv\"\n",
      "        M_legend['M7_n'] = 'Count of forum messages by day n'\n",
      "        M_legend['M8'] = 'Count of forum messages by deadline'\n",
      "        M_legend['M9_n'] = 'Proportion of all forum messages posted by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M7_M8_M9.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    cumul_array = []\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_ForumMg = []\n",
      "    df_results = []\n",
      "    \n",
      " \n",
      "# M10.\tAvg length of forum messages in 3d, 7d, 15d, 30d  (14-day trailing average)\n",
      "def engineerM10():\n",
      "    \"\"\" Finds the average length of Forum messages by that date in time (a 14-day trailing average).\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M10.csv:  table with measurements M10_3, M10_7, M10_15, M10_30 \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_ForumMgLen = pd.read_csv(\"data/cleaned/forum_msg_length.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        print\n",
      "        print \"Taking measurements from forum_msg_length.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, and it SHOULD have a total that day from the cleaned file\n",
      "                getvalue = df_ForumMgLen.loc[c,getdayseq]['MessageLen2WeekTrailingAvg'] \n",
      "            except:\n",
      "                # if can't find the exact day, then cleaned file shows no forum posts at all for this comp.\n",
      "                getvalue = 0\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty                      \n",
      "                    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M10_3','M10_7','M10_15','M10_30','M10_deadline']).to_csv('./data/cleaned/M10.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M10.csv\"\n",
      "        M_legend['M10_n'] = 'Avg length of Forum messages (14-day trailing average) at day n'        \n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M10.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    df_ForumMgLen = []\n",
      "    collectrow = []\n",
      "    measurem_array = np.empty([7,],dtype=float)   \n",
      "        \n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# M11.\tCount of valid submissions in 3d, 7d, 15d, 30d    (QueryResults1810-1814 concat)\n",
      "# M12.\tCount of valid submissions at deadline            (QueryResults1810-1814 concat)\n",
      "# M13.\tRatio of [M11]/[M12]  (relative early subm activity) \n",
      "def engineerM11_M12_M13():\n",
      "    \"\"\" Counts the number of valid submissions in a competition by 3d, 7d, 15d, 30days in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M11_M12_M13.csv:  table with measurements M11, M12 and M13\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_Submissions = pd.read_csv(\"data/cleaned/submissions.csv\",header=0)\n",
      "        df_Submissions.rename(columns={'0':'CountSubm'}, inplace=True)\n",
      "        df_Submissions.sort(['CompetitionId','DaySeq'], ascending=[1, 1], inplace=True, axis=0)\n",
      "        print\n",
      "        print \"Taking measurements from submissions.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    print \"Contains data for %d competitions,\" % len(np.unique(df_Submissions.CompetitionId))\n",
      "    print \"   constraining to %d competitions under analysis\" % len(master_compids)\n",
      "    print \"   Calculating cumulative total of Submissions per day ...\"\n",
      "    \n",
      "    t0 = time()\n",
      "    cumul_array = np.empty([3,],dtype=float)\n",
      "    for c in master_compids:\n",
      "        operate = df_Submissions.iloc[:][ (df_Submissions.CompetitionId == c) ].set_index('DaySeq')\n",
      "        cumul = 0\n",
      "        for i in operate.index.values:\n",
      "            cumul = cumul + operate.xs(i,axis=0,copy=False)['CountSubm']\n",
      "            cumul_array = np.vstack([cumul_array, [ c, i, cumul ]])\n",
      "    duration = time() - t0\n",
      "    print \"   ::done in %fs\" % duration\n",
      "    \n",
      "    cumul_array = cumul_array[1:]  # delete first row artifact from creating an np.empty\n",
      "                                   # the iterable data is now in a np.array 'cumul_array'\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq)][0,2]   #get first result in 3rd column\n",
      "                getvalue = np.float(getvalue)\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack: should be + 1, but here seek earlier than launch date\n",
      "                else:\n",
      "                    attempts = 35            #hack: should be 31, but here seek earlier than launch date\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        \n",
      "                        getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq - i)][0,2]\n",
      "                        getvalue = np.float(getvalue)\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                # so assume a value of 0\n",
      "                if i == attempts:\n",
      "                    if daycase == '-1':\n",
      "                        getvalue = np.nan\n",
      "                    else:\n",
      "                        getvalue = 0\n",
      "                    #TODO:  revisit ProspectorId comps --> several have no Subm at deadline, because a 'submission' is a prospector entry\n",
      "\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M11_3','M11_7','M11_15','M11_30','M12'])\n",
      "    df_results['M13_3'] = np.nan\n",
      "    df_results['M13_7'] = np.nan\n",
      "    df_results['M13_15'] = np.nan\n",
      "    df_results['M13_30'] = np.nan\n",
      "\n",
      "    df_results.M13_3[pd.isnull(df_results.M12) == False] = df_results.M11_3 / df_results.M12\n",
      "    df_results.M13_7[pd.isnull(df_results.M12) == False] = df_results.M11_7 / df_results.M12\n",
      "    df_results.M13_15[pd.isnull(df_results.M12) == False] = df_results.M11_15 / df_results.M12\n",
      "    df_results.M13_30[pd.isnull(df_results.M12) == False] = df_results.M11_30 / df_results.M12\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M11_M12_M13.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M11_M12_M13.csv\"\n",
      "        M_legend['M11_n'] = 'Count of valid submissions by day n'\n",
      "        M_legend['M12'] = 'Count of valid submissions by deadline'\n",
      "        M_legend['M13_n'] = 'Proportion of all valid submissions received by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M11_M12_M13.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    cumul_array = []\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_Submissions = []\n",
      "    df_results = []\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# M14.\tCount of users on teams in 3d, 7d, 15d, 30d   (QueryResults1815)\n",
      "# M15.\tCount of users on teams at Deadline           (QueryResults1815)\n",
      "# M16.  Ratio of [M14]/[M15]  (relative early team entry) \n",
      "\n",
      "# M17.\tCount of teams in 3d, 7d, 15d, 30d, deadline              (QueryResults1807)\n",
      "# M18.\tCount of multiplayer teams in 3d, 7d, 15d, 30d, deadline  (QueryResults1815 using nunique?)\n",
      "\n",
      "# M19.\tCount of [M15] where User profile contains a bio|LinkedIn|twitter|Github   (QueryResults1816)\n",
      "# M20.\tRatio of [M19]/[M15]  (user anonymity rate)  (QueryResults1816)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# M21.\tCount of RulesAcceptance in 3d, 7d, 15d, 30d  (lurkers vs players)\n",
      "def engineerM21():\n",
      "    \"\"\" Counts the number of RulesAcceptance by 3d, 7d, 15d, 30days in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M21.csv:  table with columns CompId, M21_3, M21_7, M21_15, M21_30, M21_deadline\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_CumulRuleAccepters = pd.read_csv(\"data/cleaned/rules_accepters.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        print\n",
      "        print \"Taking measurements from rules_accepters.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration, isX23 = df_Competitions.loc[c]['DurationInt'], df_Competitions.loc[c]['Is_X23']\n",
      "        collectrow = [c, duration, isX23]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "\n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = df_CumulRuleAccepters.loc[c,getdayseq]['CumulAccepted']\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 35 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack: should be + 1, but seek earlier than launch date\n",
      "                else:\n",
      "                    attempts = 35            #hack: should be 31, but apparently many times the only Rules accepters are the admins who do so before launchdate. sigh.\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_CumulRuleAccepters.loc[c,getdayseq - i]['CumulAccepted']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                if i == attempts:\n",
      "                    if (np.int(daycase) <= 30) & (np.int(daycase) > 0):    #hack: if cant find early days, assume this means 0 rules accepters\n",
      "                        getvalue = 0\n",
      "                    else:\n",
      "                        getvalue = np.nan\n",
      "\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','Is_X23','M21_3','M21_7','M21_15','M21_30','M21_deadline']).to_csv('./data/cleaned/M21.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M21.csv\"\n",
      "        M_legend['M21_n'] = 'Count of Rules Accepters by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M21.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_CumulRuleAccepters = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run it!\n",
      "#engineerM4()\n",
      "#engineerM7_M8_M9()\n",
      "engineerM10()\n",
      "#engineerM11_M12_M13()\n",
      "#engineerM21()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Taking measurements from forum_msg_length.csv:\n",
        ":: done in 0.808906s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "=  Clean output: /data/cleaned/M10.csv\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority B  (less important)\n",
      "\n",
      "# M22.\tRatio of [M14]/[M4]  (participation relative to all possible participation)\n",
      "# M23.\tRatio of [M21]/[M4]  (interest relative to all possible participation)\n",
      "# M24.\t(1 - [M14 or M15]/[21])   (relative lurker rate)\n",
      "\n",
      "\n",
      "# M25.\tCount of countries represented by submissions IP addr [or teams IP addr] (geographic diversity)\n",
      "    # (QueryResults1809 - uses Submissions table)\n",
      "# M26.\tCount of users from [M14] & [M15] for each Top 12 Kaggle countries  (QueryResults1808)\n",
      "# M27.  Count of universe of users for each Top 12 Kaggle countiries (QueryResults1560)\n",
      "# M28.  Ratio of [M26]/[M27]  (relative popularity in each country)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority C  (hard to derive)\n",
      "\n",
      "# M29.\tTOP leaderboard score at deadline (TOP since we sometimes want the min score) (QueryResults1810-1814 concat)\n",
      "# M30.\tTOP leaderboard score in 3d, 7d, 15d, 30d  (QueryResults1810-1814 concat)\n",
      "# M31.\tWORST leaderboard score in 3d, 7d, 15d, 30d\n",
      "# M32.\tMedian score in 3d, 7d, 15d, 30d\n",
      "# M33.\tRatio of [M30]/[M29]   (relative early progress of best performers)\n",
      "# M34.\tRatio of [M32]/[M29]   (relative early progress of typical performers)\n",
      "# M35.\tCount of errored submissions in 3d, 7d, 15d, 30d\n",
      "# M36.\tRatio of [M35]/[M11]  (relative user error rate)\n",
      "# M37.\t(1 \u2013 (1st place score / 2nd place score))^2 in 15d, 30d, deadline  (relative lead by #1 team)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Priority D  (maybe be a pain to get)\n",
      "\n",
      "# M38.\tNumber of data files \n",
      "# M39.\tSum of data filesizes\n",
      "# M40.\tLen(words in Evaluation page)\n",
      "# M41.\tLen(words on Data page)\n",
      "# M42.\tLen(words on Main page)\n",
      "\n",
      "# Rethink these:\n",
      "# M43.\tLen(rows) in example submission file\n",
      "# M44.\tAvg or median of (Private score - Public score)  (typical overfitting observed) - Rethink this\n",
      "# M45.\tStd Dev of Public scores in 15d, 30d    } likely to get garbage\n",
      "# M46.\tStd Dev of Private scores in 15d, 30d   }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}