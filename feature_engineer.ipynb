{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Class feature_engineer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: RJ Ramey <rj.github@garimeme.com>\n",
      "# License: (c) 2014 by RJ Ramey. All rights reserved. \n",
      "# No license is given at this time.\n",
      "#\n",
      "# Does:   Feature engineering (Create measurements: 28 derived measurements)\n",
      "#         * output: measurement csvs to ./data/cleaned/M*.csv  (ok on Github)\n",
      "#         * plot:   histograms to ./data/vis/M*.png            (ok on Github)\n",
      "\n",
      "\n",
      "# Setup and Initialization\n",
      "from datetime import datetime\n",
      "from time import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "#from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
      "\n",
      "t000 = time()\n",
      "origindate = datetime(2010, 1, 1)\n",
      "M_legend = {}\n",
      "\n",
      "# Competitions table is global; will be used throughout\n",
      "try:\n",
      "    df_Competitions = pd.read_csv(\"data/cleaned/comps.csv\", \n",
      "                                          header=0, \n",
      "                                          usecols=[0,14,15,16,17,18,19,20,24], \n",
      "                                          index_col=0)\n",
      "    master_compids = np.unique(df_Competitions.index.values)\n",
      "except IOError:\n",
      "    print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "\n",
      "# Create features\n",
      "\n",
      "# M1.\tDuration in days  = from data_cleaner, 'DurationInt'\n",
      "M_legend['DurationInt'] = 'Duration in days'\n",
      "\n",
      "# M2.\tDayofYear launchdate (seasonal behavior)  = from data_cleaner, 'DayOfYear'\n",
      "M_legend['DayOfYear'] = 'Day of calendar year in range (1,366)'\n",
      "\n",
      "# M3.\tDayOfWeek of launchdate  (weekend behavior)  = from data_cleaner, 'DayOfWeek'\n",
      "M_legend['DayOfWeek'] = 'Day of week in range (1 Mon, 7 Sun)'\n",
      "\n",
      "# M4.\tCount of valid-submitting Users globally on Kaggle as of Launch, Deadline  \n",
      "def engineerM4():\n",
      "    \"\"\" Counts the number of Users (globally on the site) who have made a valid submission by that date in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M4.csv:  table with columns CompId, M4_launch, M4_3, M4_7, M4_15, M4_30, M4_deadline \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_SubmUsersGlobal = pd.read_csv(\"data/cleaned/users_globally.csv\",header=0,usecols=[1,2],index_col=0)\n",
      "        print\n",
      "        print \"Taking measurements from users_globally.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day0','Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '0', '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a total that day from the Query\n",
      "                getvalue = df_SubmUsersGlobal.loc[getdayseq]['CumulUsers'] \n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back                \n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 1\n",
      "                else:\n",
      "                    attempts = 32\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_SubmUsersGlobal.loc[getdayseq - i]['CumulUsers']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # This can only occur if the day sought precedes any Global Users in history, so assume a value of 0\n",
      "                # Except that will cause a division by 0, so assume 1 Global User\n",
      "                if i == attempts:\n",
      "                    getvalue = 1\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty                      \n",
      "                    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M4_launch','M4_3','M4_7','M4_15','M4_30','M4_deadline'])\n",
      "        df_results.to_csv('./data/cleaned/M4.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M4.csv\"\n",
      "        M_legend['M4_n'] = 'Count of universe of all possible users (ever made a valid submission) by day n'        \n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M4.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([8,])\n",
      "    collectrow = []\n",
      "    df_SubmUsersGlobal = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "\n",
      "# M6.\tCount of forum topics in 3d, 7d, 15d, 30d, deadline\n",
      "# TODO: later\n",
      "\n",
      "# M7.\tCount of forum messages in 3d, 7d, 15d, 30d\n",
      "# M8.\tCount of forum messages at deadline\n",
      "# M9.\tRatio of [M7]/[M8]   (relative early forum activity)\n",
      "def engineerM7_M8_M9():\n",
      "    \"\"\" Counts the number of Forum messages posted in the competition by that date in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M7_M8_M9.csv:  table with measurements M7, M8 and M9 \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_ForumMg = pd.read_csv(\"data/cleaned/forum_msg.csv\",header=0)\n",
      "        df_ForumMg.rename(columns={'0':'CountMsg'}, inplace=True)\n",
      "        df_ForumMg.sort(['Id','DaySeq'], ascending=[1, 1], inplace=True, axis=0)\n",
      "        print\n",
      "        print \"Taking measurements from forum_msg.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    print \"Contains data for %d competitions,\" % len(np.unique(df_ForumMg.Id))\n",
      "    print \"   constraining to %d competitions under analysis\" % len(master_compids)\n",
      "    print \"   Calculating cumulative total of Forum messages per day ...\"\n",
      "    \n",
      "    t0 = time()\n",
      "    cumul_array = np.empty([3,],dtype=float)\n",
      "    for c in master_compids:\n",
      "        operate = df_ForumMg.iloc[:][ (df_ForumMg.Id == c) ].set_index('DaySeq')\n",
      "        cumul = 0\n",
      "        for i in operate.index.values:\n",
      "            cumul = cumul + operate.xs(i,axis=0,copy=False)['CountMsg']\n",
      "            cumul_array = np.vstack([cumul_array, [ c, i, cumul ]])\n",
      "    duration = time() - t0\n",
      "    print \"   ::done in %fs\" % duration\n",
      "    \n",
      "    cumul_array = cumul_array[1:]  # delete first row artifact from creating an np.empty\n",
      "                                   # the iterable data is now in a np.array 'cumul_array'\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq)][0,2]   #get first result in 3rd column\n",
      "                getvalue = np.float(getvalue)\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 1\n",
      "                else:\n",
      "                    attempts = 31\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        \n",
      "                        getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq - i)][0,2]\n",
      "                        getvalue = np.float(getvalue)\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                        \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now it is known there were 0 forum entries\n",
      "                if i == attempts:\n",
      "                    getvalue = 0\n",
      "\n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "\n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M7_3','M7_7','M7_15','M7_30','M8'])\n",
      "    # initialize new columns for M9\n",
      "    df_results['M9_3'] = np.nan\n",
      "    df_results['M9_7'] = np.nan\n",
      "    df_results['M9_15'] = np.nan\n",
      "    df_results['M9_30'] = np.nan\n",
      "    # calculate M9 (relative early forum activity)\n",
      "    df_results.M9_3[df_results.M8 <> 0] = df_results.M7_3 / df_results.M8\n",
      "    df_results.M9_7[df_results.M8 <> 0] = df_results.M7_7 / df_results.M8\n",
      "    df_results.M9_15[df_results.M8 <> 0] = df_results.M7_15 / df_results.M8\n",
      "    df_results.M9_30[df_results.M8 <> 0] = df_results.M7_30 / df_results.M8\n",
      "    # If a competition never had any forum messages, set all proportions to 100%\n",
      "    df_results.M9_3[df_results.M8 == 0] = 1\n",
      "    df_results.M9_7[df_results.M8 == 0] = 1\n",
      "    df_results.M9_15[df_results.M8 == 0] = 1\n",
      "    df_results.M9_30[df_results.M8 == 0] = 1\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M7_M8_M9.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M7_M8_M9.csv\"\n",
      "        M_legend['M7_n'] = 'Count of forum messages by day n'\n",
      "        M_legend['M8'] = 'Count of forum messages by deadline'\n",
      "        M_legend['M9_n'] = 'Proportion of all forum messages posted by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M7_M8_M9.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    cumul_array = []\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_ForumMg = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "    \n",
      " \n",
      "# M10.\tAvg length of forum messages in 3d, 7d, 15d, 30d  (14-day trailing average)\n",
      "def engineerM10():\n",
      "    \"\"\" Finds the average length of Forum messages by that date in time (a 14-day trailing average).\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M10.csv:  table with measurements M10_3, M10_7, M10_15, M10_30, M10_deadline \"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_ForumMgLen = pd.read_csv(\"data/cleaned/forum_msg_length.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        print\n",
      "        print \"Taking measurements from forum_msg_length.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, and it SHOULD have a total that day from the cleaned file\n",
      "                getvalue = df_ForumMgLen.loc[c,getdayseq]['MessageLen2WeekTrailingAvg'] \n",
      "            except:\n",
      "                # if can't find the exact day, then cleaned file shows no forum posts at all for this comp.\n",
      "                getvalue = 0\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty                      \n",
      "                    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M10_3','M10_7','M10_15','M10_30','M10_deadline'])\n",
      "        df_results.to_csv('./data/cleaned/M10.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M10.csv\"\n",
      "        M_legend['M10_n'] = 'Avg word length of Forum messages (14-day trailing avg) at day n'        \n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M10.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    df_ForumMgLen = []\n",
      "    collectrow = []\n",
      "    measurem_array = np.empty([7,])   \n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "\n",
      "        \n",
      "        \n",
      "# M11.\tCount of valid submissions in 3d, 7d, 15d, 30d    (QueryResults1810-1814 concat)\n",
      "# M12.\tCount of valid submissions at deadline            (QueryResults1810-1814 concat)\n",
      "# M13.\tRatio of [M11]/[M12]  (relative early subm activity) \n",
      "def engineerM11_M12_M13():\n",
      "    \"\"\" Counts the number of valid submissions in a competition by 3d, 7d, 15d, 30days in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M11_M12_M13.csv:  table with measurements M11, M12 and M13\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_Submissions = pd.read_csv(\"data/cleaned/submissions.csv\",header=0)\n",
      "        df_Submissions.rename(columns={'0':'CountSubm'}, inplace=True)\n",
      "        df_Submissions.sort(['CompetitionId','DaySeq'], ascending=[1, 1], inplace=True, axis=0)\n",
      "        print\n",
      "        print \"Taking measurements from submissions.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "    print \"Contains data for %d competitions,\" % len(np.unique(df_Submissions.CompetitionId))\n",
      "    print \"   constraining to %d competitions under analysis\" % len(master_compids)\n",
      "    print \"   Calculating cumulative total of Submissions per day ...\"\n",
      "    \n",
      "    t0 = time()\n",
      "    cumul_array = np.empty([3,],dtype=float)\n",
      "    for c in master_compids:\n",
      "        operate = df_Submissions.iloc[:][ (df_Submissions.CompetitionId == c) ].set_index('DaySeq')\n",
      "        cumul = 0\n",
      "        for i in operate.index.values:\n",
      "            cumul = cumul + operate.xs(i,axis=0,copy=False)['CountSubm']\n",
      "            cumul_array = np.vstack([cumul_array, [ c, i, cumul ]])\n",
      "    duration = time() - t0\n",
      "    print \"   ::done in %fs\" % duration\n",
      "    \n",
      "    cumul_array = cumul_array[1:]  # delete first row artifact from creating an np.empty\n",
      "                                   # the iterable data is now in a np.array 'cumul_array'\n",
      "\n",
      "    measurem_array = np.empty([7,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq)][0,2]   #get first result in 3rd column\n",
      "                getvalue = np.float(getvalue)\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 31 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack TODO: should be + 1, but here seek earlier than launch date\n",
      "                else:\n",
      "                    attempts = 35            #hack TODO: should be 31, but here seek earlier than launch date\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        \n",
      "                        getvalue = cumul_array[(cumul_array[:,0] == c) & (cumul_array[:,1] == getdayseq - i)][0,2]\n",
      "                        getvalue = np.float(getvalue)\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                # so assume a value of 0\n",
      "                if i == attempts:\n",
      "                    getvalue = 0\n",
      "\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M11_3','M11_7','M11_15','M11_30','M12'])\n",
      "    df_results['M13_3'] = np.nan\n",
      "    df_results['M13_7'] = np.nan\n",
      "    df_results['M13_15'] = np.nan\n",
      "    df_results['M13_30'] = np.nan\n",
      "    df_results.M13_3[pd.isnull(df_results.M12) == False] = df_results.M11_3 / df_results.M12\n",
      "    df_results.M13_7[pd.isnull(df_results.M12) == False] = df_results.M11_7 / df_results.M12\n",
      "    df_results.M13_15[pd.isnull(df_results.M12) == False] = df_results.M11_15 / df_results.M12\n",
      "    df_results.M13_30[pd.isnull(df_results.M12) == False] = df_results.M11_30 / df_results.M12\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M11_M12_M13.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M11_M12_M13.csv\"\n",
      "        M_legend['M11_n'] = 'Count of valid submissions by day n'\n",
      "        M_legend['M12'] = 'Count of valid submissions by deadline'\n",
      "        M_legend['M13_n'] = 'Proportion of all valid submissions received by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M11_M12_M13.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    cumul_array = []\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_Submissions = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "\n",
      "# M14.\tCount of users on teams in 3d, 7d, 15d, 30d   (QueryResults1815)\n",
      "# M15.\tCount of users on teams at Deadline           (QueryResults1815)\n",
      "# M16.  Ratio of [M14]/[M15]  (relative early team entry)\n",
      "# M43.\tCount of [M15] where User profile contains a bio|LinkedIn|twitter|Github (QueryResults1816)\n",
      "# M20.\tRatio of 1 - [M43]/[M15]  (user anonymity rate)  (QueryResults1816)\n",
      "\n",
      "def engineerM14_M15_M16_M20():\n",
      "    \"\"\" \n",
      "     Counts the number of teamed users in a competition by 3d, 7d, 15d, 30days in time.\n",
      "     Counts the number of teamed users with a bio in their Profile.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M14_M15_M16_M20.csv:  table with measurements M14, M15, M16 and M20\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_CumulTeamsUsers = pd.read_csv(\"data/cleaned/teams_users.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        df_CumulTeamsUsersBios = pd.read_csv(\"data/cleaned/teams_users_bios.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        print\n",
      "        print \"Taking measurements from teams_users.csv and teams_users_bios.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        collectrow = [c, duration]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "                \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = df_CumulTeamsUsers.loc[c,getdayseq]['CumulTeamsUsers']\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 35 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack TODO\n",
      "                else:\n",
      "                    attempts = 35            #hack TODO\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_CumulTeamsUsers.loc[c,getdayseq - i]['CumulTeamsUsers']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                if i == attempts:\n",
      "                    if (np.int(daycase) <= 30) & (np.int(daycase) > 0):    #TODO hack\n",
      "                        getvalue = 0\n",
      "                    else:\n",
      "                        getvalue = np.nan\n",
      "            collectrow.append(getvalue)\n",
      "            \n",
      "        # AND DO ONCE:\n",
      "        # Seek again the value of DayEnd from the competition\n",
      "        getdayseq = df_Competitions.loc[c]['DayEnd']  \n",
      "        try:\n",
      "            getvalue = df_CumulTeamsUsersBios.loc[c,getdayseq]['CumulTeamsUsersBios']\n",
      "        except:\n",
      "            # roll back in time to fetch total from the previous day, up 5 days before launch\n",
      "            i = 1\n",
      "            attempts = duration + 5  #hack TODO                    \n",
      "            while (i < attempts):\n",
      "                try:\n",
      "                    getvalue = df_CumulTeamsUsersBios.loc[c,getdayseq - i]['CumulTeamsUsersBios']\n",
      "                    # found it! break the loop\n",
      "                    break\n",
      "                except:\n",
      "                    # roll back another day\n",
      "                    i = i + 1\n",
      "            \n",
      "            # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "            # so now ...\n",
      "            if i == attempts:\n",
      "                getvalue = 0\n",
      "                \n",
      "        collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "        \n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M14_3','M14_7','M14_15','M14_30','M15','M43'])\n",
      "    # initialize new columns for M16 and M20\n",
      "    df_results['M16_3'] = np.nan\n",
      "    df_results['M16_7'] = np.nan\n",
      "    df_results['M16_15'] = np.nan\n",
      "    df_results['M16_30'] = np.nan\n",
      "    df_results['M20'] = np.nan\n",
      "    # calculate M16 (relative early team entry) \n",
      "    df_results.M16_3[df_results.M15 <> 0] = df_results.M14_3 / df_results.M15\n",
      "    df_results.M16_7[df_results.M15 <> 0] = df_results.M14_7 / df_results.M15\n",
      "    df_results.M16_15[df_results.M15 <> 0] = df_results.M14_15 / df_results.M15\n",
      "    df_results.M16_30[df_results.M15 <> 0] = df_results.M14_30 / df_results.M15\n",
      "    # calculate M20 (user anonymity rate) \n",
      "    df_results.M20[df_results.M15 <> 0] = 1 - (df_results.M43 / df_results.M15)\n",
      "    # If a competition never had any users on teams, set all proportions to 100%\n",
      "    df_results.M16_3[df_results.M15 == 0] = 1\n",
      "    df_results.M16_7[df_results.M15 == 0] = 1\n",
      "    df_results.M16_15[df_results.M15 == 0] = 1\n",
      "    df_results.M16_30[df_results.M15 == 0] = 1\n",
      "    df_results.M20[df_results.M15 == 0] = 1\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M14_M15_M16_M20.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M14_M15_M16_M20.csv\"\n",
      "        M_legend['M14_n'] = 'Participants on teams by day n'\n",
      "        M_legend['M15'] = 'Participants on teams by deadline'\n",
      "        M_legend['M16_n'] = 'Proportion of participants achieved by day n'\n",
      "        M_legend['M43'] = 'Participants on teams with a bio|LinkedIn|twitter|Github, at deadline'\n",
      "        M_legend['M20'] = 'Proportion of anonymous users'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M14_M15_M16_M20.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_CumulTeamsUsers = []\n",
      "    df_CumulTeamsUsersBios = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "\n",
      "\n",
      "# M17.\tCount of multiplayer teams at deadline\n",
      "# M18.\tCount of teams in 3d, 7d, 15d, 30d, deadline  (QueryResults1807)\n",
      "# M19.  Ratio of [M17]/[M18]  (Proportion of multiplayer teams) \n",
      "def engineerM17_M18_M19():\n",
      "    \"\"\" Counts the number of (multiplayer) teams in a competition by 3d, 7d, 15d, 30days in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M17_M18_M19.csv:  table with measurements M17, M18 and M19\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_CumulTeams = pd.read_csv(\"data/cleaned/teams.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        df_MultiTeams = pd.merge(df_Competitions,\n",
      "                                 pd.read_csv(\"data/cleaned/teams_multiplayer.csv\",header=0),\n",
      "                                 left_on=df_Competitions.index,\n",
      "                                 right_on='CompetitionId',\n",
      "                                 how='left')\n",
      "        df_MultiTeams.fillna(value=0,inplace=True)\n",
      "        df_MultiTeams.set_index('CompetitionId', drop=True, inplace=True)\n",
      "        print\n",
      "        print \"Taking measurements from teams.csv and teams_multiplayer.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    df_MultiTeams.rename(columns={'0':'CountMultiTeam'}, inplace=True)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration = df_Competitions.loc[c]['DurationInt']\n",
      "        countmulti = df_MultiTeams.loc[c]['CountMultiTeam']\n",
      "        collectrow = [c, duration, countmulti]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "                \n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = df_CumulTeams.loc[c,getdayseq]['CumulTeams']\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 35 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack TODO\n",
      "                else:\n",
      "                    attempts = 35            #hack TODO\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_CumulTeams.loc[c,getdayseq - i]['CumulTeams']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                if i == attempts:\n",
      "                    if (np.int(daycase) <= 30) & (np.int(daycase) > 0):    #hack TODO\n",
      "                        getvalue = 0\n",
      "                    else:\n",
      "                        getvalue = np.nan\n",
      "\n",
      "                \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M17','M18_3','M18_7','M18_15','M18_30','M18_deadline'])\n",
      "    # initialize new columns for M19\n",
      "    df_results['M19'] = np.nan\n",
      "    # calculate M19 (Proportion of multiplayer teams) \n",
      "    df_results.M19[df_results.M18_deadline <> 0] = df_results.M17 / df_results.M18_deadline\n",
      "    # If a competition never had any teams, set all proportions to 0%\n",
      "    df_results.M19[df_results.M18_deadline == 0] = 0\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M17_M18_M19.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M17_M18_M19.csv\"\n",
      "        M_legend['M17'] = 'Count of multiplayer teams by deadline'\n",
      "        M_legend['M18_n'] = 'Count of participating teams by day n'\n",
      "        M_legend['M19'] = 'Proportion of multiplayer teams'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M17_M18_M19.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_CumulTeams = []\n",
      "    df_MultiTeams = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop('DurationInt',axis=1)\n",
      "\n",
      "\n",
      "\n",
      "# M21.\tCount of RulesAcceptance in 3d, 7d, 15d, 30d  (lurkers vs players)\n",
      "def engineerM21():\n",
      "    \"\"\" Counts the number of RulesAcceptance by 3d, 7d, 15d, 30days in time.\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M21.csv:  table with columns CompId, M21_3, M21_7, M21_15, M21_30, M21_deadline\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_CumulRuleAccepters = pd.read_csv(\"data/cleaned/rules_accepters.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "        print\n",
      "        print \"Taking measurements from rules_accepters.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    measurem_array = np.empty([8,],dtype=float)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        duration, isX23 = df_Competitions.loc[c]['DurationInt'], df_Competitions.loc[c]['Is_X23']\n",
      "        collectrow = [c, duration, isX23]\n",
      "        collectcolumns = ['Day3','Day7','Day15','Day30','DayEnd']\n",
      "      \n",
      "        for M in collectcolumns:\n",
      "            daycase = M[3:]           #values will be strings '3', '7', '15', '30', 'End'\n",
      "            daycase = '-1' if (daycase == 'End') else daycase\n",
      "            \n",
      "            # if I shouldnt be fetching this Measurement at X_days b/c the comp already ended, then fetch the deadline number \n",
      "            if np.int(daycase) > duration:\n",
      "                getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            else:\n",
      "                getdayseq = df_Competitions.loc[c][M]\n",
      "\n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "                getvalue = df_CumulRuleAccepters.loc[c,getdayseq]['CumulAccepted']\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day, up to 35 days back\n",
      "                i = 1\n",
      "                if daycase == '-1':          #If seeking the DayEnd (deadline) value, then roll back more times than normal\n",
      "                    attempts = duration + 5  #hack TODO: should be + 1, but seek earlier than launch date\n",
      "                else:\n",
      "                    attempts = 35            #hack TODO: should be 31, but apparently many times the only Rules accepters are the admins who do so before launchdate. sigh.\n",
      "                    \n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = df_CumulRuleAccepters.loc[c,getdayseq - i]['CumulAccepted']\n",
      "                        # found it! break the loop\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                \n",
      "                # At this point in code, I tried referencing the exact day's value (not found), then 1-31 days back (also not found),\n",
      "                # so now ...\n",
      "                if i == attempts:\n",
      "                    if (np.int(daycase) <= 30) & (np.int(daycase) > 0):    #hack TODO: if cant find early days, assume this means 0 rules accepters\n",
      "                        getvalue = 0\n",
      "                    else:\n",
      "                        getvalue = np.nan\n",
      " \n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results = pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','Is_X23','M21_3','M21_7','M21_15','M21_30','M21_deadline'])\n",
      "        df_results.to_csv('./data/cleaned/M21.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M21.csv\"\n",
      "        M_legend['M21_n'] = 'Count of rules accepters by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M21.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    measurem_array = np.empty([7,])\n",
      "    collectrow = []\n",
      "    df_CumulRuleAccepters = []\n",
      "    # Return concise form\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results.drop(['DurationInt','Is_X23'],axis=1)\n",
      "\n",
      "\n",
      "# M22.\tRatio of [M14]/[M4]  (participation relative to all possible participation)\n",
      "# M23.\tRatio of [M21]/[M4]  (interest relative to all possible participation)\n",
      "# M24.\t(1 - [M14]/[M21])   (relative lurker rate)\n",
      "def engineerM22_M23_M24():\n",
      "    \"\"\" \n",
      "     Calculates participation, relative to universe of all possible participants.\n",
      "     (Essentially: a 'user market share')\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M22_M23_M24.csv:  table with columns for periodic measurements:\n",
      "                     M22_3, M22_7, M22_15, M22_30, M22_deadline\n",
      "                     M23_3, M23_7, M23_15, M23_30, M23_deadline\n",
      "                     M24_3, M24_7, M24_15, M24_30, M24_deadline\"\"\"\n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_M4 = pd.read_csv(\"data/cleaned/M4.csv\",header=0, usecols=[1,3,4,5,6,7,8])\n",
      "        df_M14 = pd.read_csv(\"data/cleaned/M14_M15_M16_M20.csv\",header=0, usecols=[1,3,4,5,6,7,8])\n",
      "        df_M21 = pd.read_csv(\"data/cleaned/M21.csv\",header=0, usecols=[1,4,5,6,7,8])\n",
      "        df_results = pd.merge(df_M14, df_M4,left_on='CompetitionId',right_on='CompetitionId',how='inner')\n",
      "        df_results = pd.merge(df_results, df_M21,left_on='CompetitionId',right_on='CompetitionId',how='inner')\n",
      "        df_results.set_index('CompetitionId',drop=True, inplace=True)\n",
      "        df_M4 = []\n",
      "        df_M14 = []\n",
      "        df_M21 = []\n",
      "        print\n",
      "        print \"Taking additional measurements, ratios of earlier measurements:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing inputs from earlier steps. Run after engineerM4(), engineerM14_M15_M16_M20() and engineerM21().\"\n",
      "    \n",
      "    # initialize new columns via a list of features (15 elements)\n",
      "    features = []\n",
      "    for m in range(22,25):\n",
      "        for d in ('3', '7', '15', '30', 'deadline'):\n",
      "            features.append( 'M' + (str(m) + '_' + d) )\n",
      "    for f in features:\n",
      "        df_results[f] = np.nan\n",
      "    \n",
      "    # Recall that\n",
      "    # M22.\tRatio of [M14]/[M4]   (users on teams / global universe of users)\n",
      "    # M23.\tRatio of [M21]/[M4]   (rules accepters / global universe of users)\n",
      "    # M24.\t1 - [M14]/ ([M21]+1)      1 - (users on teams) / ('users who browsed')  = lurker rate\n",
      "    \n",
      "    m14 = ['M14_3', 'M14_7', 'M14_15', 'M14_30', 'M15']\n",
      "    m4 =  ['M4_3',  'M4_7',  'M4_15',  'M4_30',  'M4_deadline']\n",
      "    m21 = ['M21_3', 'M21_7', 'M21_15', 'M21_30', 'M21_deadline']\n",
      "    \n",
      "    for i in range(0,5):\n",
      "        # calc M22  - note: its already certain that values of M4 are never 0\n",
      "        df_results[features[i]] = df_results[m14[i]] / df_results[m4[i]]\n",
      "        # calc M23\n",
      "        df_results[features[i+5]] = df_results[m21[i]] / df_results[m4[i]]\n",
      "        # calc M24  - note: add 1 to denominator so it is never 0\n",
      "        \n",
      "        df_results[features[i+10]][ df_results[m21[i]]<>0 ] = 1 - (df_results[m14[i]] / (df_results[m21[i]]))  #TODO: when M21 is 0, this causes Neg Values\n",
      "        #except ZeroDivisionError:\n",
      "        \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_results = df_results.drop(['M14_3','M14_7','M14_15','M14_30','M15','M43','M4_launch','M4_3','M4_7','M4_15','M4_30','M4_deadline','M21_3','M21_7','M21_15','M21_30','M21_deadline'], axis=1)\n",
      "        df_results.to_csv('./data/cleaned/M22_M23_M24.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M22_M23_M24.csv\"\n",
      "        M_legend['M22_n'] = 'Ratio of participants to total users universe by day n'\n",
      "        M_legend['M23_n'] = 'Ratio of rules accepters to total users universe by day n'\n",
      "        M_legend['M24_n'] = 'Ratio of lurkers by day n'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M22_M23_M24.csv\"\n",
      "        print\n",
      "    \n",
      "    # Reclaim memory\n",
      "    features = []\n",
      "    m4 = []\n",
      "    m14 = []\n",
      "    m21 = []\n",
      "    # Return concise form\n",
      "    return df_results\n",
      "\n",
      "# M25.\tCount of countries represented by participants (geographic diversity)\n",
      "    # (QueryResults1809 - uses Submissions table IP addr)   # TODO: use teams IP addr?\n",
      "def engineerM25():\n",
      "    \"\"\" Counts the number of countries represented by participants, as tracked by IP address of submissions\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M25.csv:  table with columns CompetitionId, M25\"\"\"\n",
      "    \n",
      "    t0 = time()\n",
      "    try:\n",
      "        df_Countries = pd.read_csv(\"data/cleaned/users_countries_all.csv\",header=0,usecols=[0,2],index_col=0)\n",
      "        df_Countries.rename(columns={'Count_Countries':'M25'}, inplace=True)\n",
      "        print\n",
      "        print \"Taking measurements from users_countries_all.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    try:\n",
      "        df_Countries.to_csv('./data/cleaned/M25.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M25.csv\"\n",
      "        M_legend['M25'] = 'Number of countries represented by participants'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M25.csv\"\n",
      "        print\n",
      "\n",
      "    # Return concise form\n",
      "    return df_Countries\n",
      "\n",
      "\n",
      "# M26.\tCount of users on teams at deadline in Major countries  (QueryResults1808)\n",
      "        # TODO?: or Count of users on submitting teams at deadline in Major countries  (QueryResults1835) (numbers slightly lower)\n",
      "# M27.  Count of universe of users in Major countries at deadline (QueryResults1560)\n",
      "# M28.  Ratio of [M26]/[M27]  (relative popularity in each major country)\n",
      "def engineerM26_M27_M28():\n",
      "    \"\"\" Counts the number participants from major countries, as tracked by IP address of submissions\n",
      "    \n",
      "    Outputs:\n",
      "      /cleaned/M26_M27_M28.csv:  table with columns CompetitionId, M26, M27, M28\"\"\"\n",
      "    \n",
      "    try:\n",
      "        df_Countries = pd.read_csv(\"data/cleaned/users_countries.csv\",header=0)\n",
      "        df_CountriesGlobal = pd.read_csv(\"data/cleaned/users_globally_countries.csv\",header=0, usecols=[1,2,3])\n",
      "        print\n",
      "        print \"Taking measurements from users_countries.csv  &  users_globally_countries.csv:\"\n",
      "    except IOError:\n",
      "        print \"WARNING: Missing required inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "    \n",
      "    # Create M26\n",
      "    t0 = time()\n",
      "    print \"Counting participants from major countries ...\"\n",
      "    # drop null entries\n",
      "    df_Countries = df_Countries.dropna(axis=0,how='any')\n",
      "    # create pivot, rows -> columns\n",
      "    df_Countries.set_index(['Id','Country'], drop=False, inplace=True, verify_integrity=True)\n",
      "    df_Countries = df_Countries.pivot_table(rows='Id', cols='Country', values='CountUserIdsOnTeams', fill_value=0)\n",
      "    # rename to M26_\n",
      "    renames = { colname : 'M26_' + colname for colname in df_Countries.columns } \n",
      "    df_Countries.rename(columns=renames, inplace=True)\n",
      "\n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "    \n",
      "    # Create M27\n",
      "    t0 = time()\n",
      "    print \"Counting global users present by that date ...\"\n",
      "    # move to np.array for speed\n",
      "    measurem_array = np.empty([ len(np.unique(df_CountriesGlobal.Country.values))+1 ,],dtype=float)\n",
      "    df_CountriesGlobal.set_index(['Country','DaySeq'], drop=False, inplace=True)\n",
      "    df_CountriesGlobal.sort_index(axis=0, ascending=True, inplace=True)\n",
      "    data_array = df_CountriesGlobal.values\n",
      "    \n",
      "    collectcolumns = np.unique(df_CountriesGlobal.Country.values).tolist()\n",
      "    columnheadings = ['CompetitionId']\n",
      "    columnheadings.extend('M27_' + ctry for ctry in collectcolumns)\n",
      "    \n",
      "    for c in master_compids:\n",
      "        collectrow = [c]\n",
      "        for ctry in collectcolumns:\n",
      "            # grab last day of the comp, use that to find in array\n",
      "            getdayseq = df_Competitions.loc[c]['DayEnd']\n",
      "            try:\n",
      "                # attempt to fetch value, but it may not have a total that day in the Query\n",
      "                getvalue = float(data_array[ (data_array[:,0] == ctry) & (data_array[:,1] == getdayseq), 2])\n",
      "            except:\n",
      "                # roll back in time to fetch total from the previous day               \n",
      "                i = 1\n",
      "                attempts = getdayseq - 1\n",
      "                while (i < attempts):\n",
      "                    try:\n",
      "                        getvalue = float(data_array[ (data_array[:,0] == ctry) & (data_array[:,1] == getdayseq-i), 2])\n",
      "                        break\n",
      "                    except:\n",
      "                        # roll back another day\n",
      "                        i = i + 1\n",
      "                # At this point in code, I tried referencing the exact day's value (not found), back to Day0 (never found)\n",
      "                # This means there were no Global users ever for that country, \n",
      "                #  so assume a value 0, except that will cause a division by 0, so assume 1 User\n",
      "                if i == attempts:\n",
      "                    getvalue = 1\n",
      "            collectrow.append(getvalue)\n",
      "        measurem_array = np.vstack([measurem_array, collectrow])\n",
      "    measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty  \n",
      "    # Completely replace earlier dataframe\n",
      "    df_CountriesGlobal = pd.DataFrame(data=measurem_array, columns=columnheadings)\n",
      "    \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "\n",
      "    # Create M28\n",
      "    t0 = time()\n",
      "    print \"Calculating ratios ...\"\n",
      "    df_results = pd.merge(df_Countries, df_CountriesGlobal, left_on=df_Countries.index, right_on='CompetitionId', how='inner')\n",
      "    # initialize new columns via a list of feature names\n",
      "    m26 = []\n",
      "    m27 = []\n",
      "    m28 = []\n",
      "    for ctry in collectcolumns:\n",
      "        m26.append( 'M26_' + ctry )\n",
      "        m27.append( 'M27_' + ctry )\n",
      "        m28.append( 'M28_' + ctry )\n",
      "    \n",
      "    for i in range(0, len(collectcolumns) ):\n",
      "        df_results[m28[i]] = np.nan\n",
      "        # calc M28  - note: its already certain that values of M27 are never 0\n",
      "        df_results[m28[i]] = df_results[m26[i]] / df_results[m27[i]]\n",
      "\n",
      "        # few instances (early 2010) while # of global users is <5, a difference in source queries causes '200%'\n",
      "        # (forgivable) hack: constrain these to 100%\n",
      "        z = len(df_results[m28[i]][ df_results[m28[i]] > 1 ])\n",
      "        if z > 0:\n",
      "            print \"  Note: %d ratios are >100%%. Clamping to 100%%\" % z\n",
      "            df_results[m28[i]][ df_results[m28[i]] > 1 ] = 1\n",
      "        \n",
      "    duration = time() - t0\n",
      "    print \":: done in %fs\" % duration\n",
      "\n",
      "    try:\n",
      "        df_results.to_csv('./data/cleaned/M26_M27_M28.csv') \n",
      "        print \"=  Clean output: /data/cleaned/M26_M27_M28.csv\"\n",
      "        M_legend['M26_cc'] = 'Count of participants in this country at deadline'\n",
      "        M_legend['M27_cc'] = 'Count of universe of all possible users in this country at deadline'\n",
      "        M_legend['M28_cc'] = 'Relative popularity in each country'\n",
      "    except IOError:\n",
      "        print \"WARNING: Failed to write out file: /data/cleaned/M26_M27_M28.csv\"\n",
      "        print\n",
      "    \n",
      "    # Return concise form\n",
      "    for i in range(0, len(collectcolumns) ):\n",
      "        # now M26 & M27 are no longer needed\n",
      "        df_results = df_results.drop(m26[i], axis=1)\n",
      "        df_results = df_results.drop(m27[i], axis=1)\n",
      "    df_results.set_index('CompetitionId',inplace=True)\n",
      "    return df_results\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run it!\n",
      "t000 = time()\n",
      "#df_M4 = engineerM4()\n",
      "#df_M7 = engineerM7_M8_M9()\n",
      "#df_M10 = engineerM10()\n",
      "#df_M11 = engineerM11_M12_M13()\n",
      "#df_M14 = engineerM14_M15_M16_M20()\n",
      "#df_M17 = engineerM17_M18_M19()\n",
      "#df_M21 = engineerM21()\n",
      "#df_M22 = engineerM22_M23_M24()\n",
      "#df_M25 = engineerM25()\n",
      "df_M26 = engineerM26_M27_M28()\n",
      "duration = time() - t000\n",
      "\n",
      "# Assemble final clean set:\n",
      "df_Final = pd.merge(df_Competitions, df_M26, left_index=True, right_index=True, how='left', copy=False) # df_M26 has fewer rows\n",
      "for df in [df_M7, df_M10, df_M11, df_M14, df_M17, df_M21, df_M22, df_M25]:\n",
      "    df_Final = pd.merge(df_Final, df, left_index=True, right_index=True, how='inner', copy=False)\n",
      "\n",
      "# Final cull of unneeded columns\n",
      "df_Final = df_Final.drop(['Is_X23','M17','M11_3','M11_7','M11_15','M11_30','M14_3','M14_7','M14_15','M14_30'],axis=1)\n",
      "df_Final = df_Final.drop(['Day0','Day3','Day7','Day15','Day30','DayEnd'],axis=1)\n",
      "df_Final.sort_index(axis=0, ascending=True, inplace=True)\n",
      "print \"Final table has %d rows, %d columns\" % (df_Final.shape[0] , df_Final.shape[1])\n",
      "\n",
      "try:\n",
      "    df_Final.to_csv(\"data/cleaned/Final.csv\")\n",
      "    print \"=  FINAL output:  data/clean/Final.csv\"\n",
      "except:\n",
      "    print \"WARNING: Failed to write out file: /data/cleaned/Final.csv\"\n",
      "    print\n",
      "\n",
      "print\n",
      "print \"====================================================\"\n",
      "print \"FEATURE_ENGINEER COMPLETE! Finished in %fs     \u10da(\u2579\u25e1\u2579\u10da)\" % duration\n",
      "print \"====================================================\"\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Taking measurements from users_countries.csv  &  users_globally_countries.csv:\n",
        "Counting participants from major countries ...\n",
        ":: done in 0.082880s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Counting global users present by that date ...\n",
        ":: done in 10.270716s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Calculating ratios ...\n",
        "  Note: 1 ratios compute >100%. Clamping to 1 ...\n",
        "  Note: 1 ratios compute >100%. Clamping to 1 ...\n",
        "  Note: 2 ratios compute >100%. Clamping to 1 ...\n",
        ":: done in 0.021963s\n",
        "=  Clean output: /data/cleaned/M26_M27_M28.csv\n",
        "Final table has 366 rows, 66 columns"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "=  FINAL output:  data/clean/Final.csv\n",
        "\n",
        "====================================================\n",
        "FEATURE_ENGINEER COMPLETE! Finished in 10.426808s     \u10da(\u2579\u25e1\u2579\u10da)\n",
        "====================================================\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority C  (hard to derive)\n",
      "\n",
      "# M29.\tTOP leaderboard score at deadline (TOP since we sometimes want the min score) (QueryResults1810-1814)\n",
      "# M30.\tTOP leaderboard score in 3d, 7d, 15d, 30d  (QueryResults1810-1814)\n",
      "# M31.\tWORST leaderboard score in 3d, 7d, 15d, 30d\n",
      "# M32.\tMedian score in 3d, 7d, 15d, 30d\n",
      "# M33.\tRatio of [M30]/[M29]   (relative early progress of best performers)\n",
      "# M34.\tRatio of [M32]/[M29]   (relative early progress of typical performers)\n",
      "# M35.\tCount of errored submissions in 3d, 7d, 15d, 30d\n",
      "# M36.\tRatio of [M35]/[M11]  (relative user error rate)\n",
      "# M37.\t(1 \u2013 (1st place score / 2nd place score))^2 in 15d, 30d, deadline  (relative lead by #1 team)\n",
      "\n",
      "# Priority D  (maybe be a pain to get)\n",
      "\n",
      "# M38.\tNumber of data files \n",
      "# M39.\tSum of data filesizes\n",
      "# M40.\tLen(words in Evaluation page)\n",
      "# M41.\tLen(words on Data page)\n",
      "# M42.\tLen(words on Main page)\n",
      "\n",
      "# Rethink these:\n",
      "# M100.\tLen(rows) in example submission file\n",
      "# M101.\tAvg or median of (Private score - Public score)  (typical overfitting observed) - Rethink this\n",
      "# M102.\tStd Dev of Public scores in 15d, 30d    } likely to get garbage\n",
      "# M103.\tStd Dev of Private scores in 15d, 30d   }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M_legend"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "{'DayOfWeek': 'Day of week in range (1 Mon, 7 Sun)',\n",
        " 'DayOfYear': 'Day of calendar year in range (1,366)',\n",
        " 'DurationInt': 'Duration in days',\n",
        " 'M26_cc': 'Count of participants in this country at deadline',\n",
        " 'M27_cc': 'Count of universe of all possible users in this country at deadline',\n",
        " 'M28_cc': 'Relative popularity in each country'}"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}