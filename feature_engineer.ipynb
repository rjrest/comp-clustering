{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#   * Feature engineering  (20-45 derived measurements)\n",
      "#     * output: measurement csvs to ./data/cleaned/  (ok on Github)\n",
      "#     * plot:   histograms to ./data/vis/  (ok on Github)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Class feature_engineer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: RJ Ramey <rj.github@garimeme.com>\n",
      "# License: (c) 2014 by RJ Ramey. All rights reserved. No license is given at this time.\n",
      "\n",
      "# Setup and Initialization\n",
      "from datetime import datetime\n",
      "from time import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "#from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create measurements\n",
      "\n",
      "# Create features, priority A  (more important or easy to include)\n",
      "\n",
      "# M1.\tNumber of data files A \n",
      "# M2.\tSum of data filesizes A\n",
      "# M3.\tDuration in days (Deadline - DateEnabled) A\n",
      "#    NOTE: M3 is created in function data_cleaner\n",
      "\n",
      "# M4.\tCount of submitting Users globally at DateEnabled A\n",
      "# M5.\tCount of submitting Users globally at Deadline A\n",
      "\n",
      "# M9.\tCount of forum topics in 3d, 7d, 14d, 30d A\n",
      "# M10.\tCount of forum postings in 3d, 7d, 14d, 30d A\n",
      "# M11.\tCount of forum postings at deadline A\n",
      "# M12.\tRatio of [10]/[11]   (relative early forum activity) \n",
      "# M13.\tCount of (valid) submissions in 3d, 7d, 14d, 30d\n",
      "# M14.\tCount of (valid) submissions at deadline\n",
      "# M15.\tRatio of [13]/[14]  (relative early subm activity) \n",
      "# M16.\tCount of users on teams in 3d, 7d, 14d, 30d, deadline\n",
      "\n",
      "# M28.\tDayofYear launchdate  (seasonal behavior)A\n",
      "#    NOTE: M28 is created in function data_cleaner\n",
      "# M29.\tDayOfWeek of launchdate  (weekend behavior)A\n",
      "#    NOTE: M29 is created in function data_cleaner\n",
      "\n",
      "\n",
      "# M32.\tCount of teams in 3d, 7d, 14d, 30d, deadline A\n",
      "# M33.\tCount of multiplayer teams in 3d, 7d, 14d, 30d, deadline A\n",
      "\n",
      "# M42.\tCount of users on teams at Deadline A\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority B  (less important)\n",
      "\n",
      "# M17.\tTOP leaderboard score at deadline \u2013 (TOP LB score since we sometimes want the min score)\n",
      "# M18.\tTOP leaderboard score in 3d, 7d, 14d, 30d\n",
      "# M19.\tWORST leaderboard score in 3d, 7d, 14d, 30d B\n",
      "# M20.\tAvg score in 3d, 7d, 14d, 30d B\n",
      "# M21.\tMedian score in 3d, 7d, 14d, 30d B\n",
      "# M22.\tRatio of [18]/[17]   (relative early progress of best performers)\n",
      "# M23.\tRatio of [21]/[17]   (relative early progress of typical performers) B\n",
      "# M26.\tCount of errored submissions in 3d, 7d, 14d, 30d B\n",
      "# M27.\tRatio of [26]/[13]  (relative user error rate) B\n",
      "# M39.\tStd Dev of Public scores in 14d, 30d B, likely to get garbage\n",
      "# M40.\tStd Dev of Private scores in 14d, 30d B\n",
      "# M43.\tCount of [42] where User profile contains a bio|LinkedIn|twitter|Github B\n",
      "# M44.\tRatio of [43]/[42]  (user anonymity rate)\u2014says something about which part of Kaggle community it attracts, B\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority C  (hard, meaning a bit of computational/SQL effort to get, may be too large)\n",
      "\n",
      "# M24.\tAvg length of all forum posts in 3d, 7d, 14d, 30d\n",
      "\n",
      "# M30.\tCount of RulesAcceptance in 3d, 7d, 14d, 30d C, but could be interesting: lurkers vs players\n",
      "\n",
      "t0 = time()\n",
      "try:\n",
      "    df_CumulRuleAccepters = pd.read_csv(\"data/cleaned/rules_accepters.csv\",header=0, usecols=[1,2,3], index_col=[0,1])\n",
      "    df_Competitions = pd.read_csv(\"data/cleaned/comps.csv\",header=0, usecols=[0,15,16,17,18,19,20,24], index_col=0)\n",
      "    print\n",
      "    print \"Taking measurements from rules_accepters.csv :\"\n",
      "except IOError:\n",
      "    print \"WARNING: Missing inputs from /data/cleaned. Run data_cleaner first.\"\n",
      "\n",
      "unique_comps = np.unique(df_Competitions.index.values)\n",
      "measurem_array = np.empty([7,],dtype=float)\n",
      "\n",
      "for c in unique_comps:\n",
      "    duration = df_Competitions.loc[c]['DurationInt']\n",
      "    collectrow = [c, duration]\n",
      "    collectcolumns = ['Day3','Day7','Day14','Day30','DeadlineDaySeq']\n",
      "  \n",
      "    for M in collectcolumns:\n",
      "        getdayseq = df_Competitions.loc[c][M]\n",
      "            \n",
      "        try:\n",
      "            # attempt to fetch value, but it may not have a unique total that day from the Query\n",
      "            getvalue = df_CumulRuleAccepters.loc[c,getdayseq]['CumulAccepted']\n",
      "        except:\n",
      "            # roll back in time to fetch total from the previous day, up to 30 days back\n",
      "            i = 1\n",
      "            if M == 'DeadlineDaySeq':\n",
      "                attempts = duration\n",
      "            else:\n",
      "                attempts = 31\n",
      "                \n",
      "            while (i < attempts):\n",
      "                try:\n",
      "                    getvalue = df_CumulRuleAccepters.loc[c,getdayseq - i]['CumulAccepted']\n",
      "                    # found it! break the loop\n",
      "                    break\n",
      "                except:\n",
      "                    # roll back another day\n",
      "                    i = i + 1\n",
      "                getvalue = np.nan\n",
      "            if i == 31:\n",
      "                getvalue = np.nan\n",
      "\n",
      "        if (duration < 7) & (M[3:] == '7'):\n",
      "            getvalue = np.nan                \n",
      "        if (duration < 14) & (M[3:] == '14'):\n",
      "            getvalue = np.nan\n",
      "        if (duration < 30) & (M[3:] == '30'):\n",
      "            getvalue = np.nan\n",
      "            \n",
      "        collectrow.append(getvalue)\n",
      "    measurem_array = np.vstack([measurem_array, collectrow])\n",
      "measurem_array = measurem_array[1:]  # delete first row artifact from creating an np.empty   \n",
      "\n",
      "duration = time() - t0\n",
      "print \"...done in %fs\" % duration\n",
      "\n",
      "try:\n",
      "    pd.DataFrame(data=measurem_array, columns=['CompetitionId','DurationInt','M30_3','M30_7','M30_14','M30_30','M30_deadline']).to_csv('./data/cleaned/M30.csv') \n",
      "    print\n",
      "    print \"=  Clean output : /data/cleaned/M30.csv\"\n",
      "except IOError:\n",
      "    print \"WARNING: Failed to write out file: data/cleaned/M30.csv\"\n",
      "    print\n",
      "\n",
      "# Reclaim memory\n",
      "#measurem_array = np.empty([5,])\n",
      "#collect = []\n",
      "#df_CumulRuleAccepters = []\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# M31.\t(1 - [16]/[30])   (relative dropout rate) C\n",
      "# M36.\tCount of geolocated countries of users from [16] A, C \u2013 query will take quite a while\n",
      "# M37.\tCount of users from [16] for each Top 10 countries in [36]\n",
      "# M41.\t(1 \u2013 (1st place score / 2nd place score))^2 in 14d, 30d, deadline  (relative lead by #1 team)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Taking measurements from rules_accepters.csv :\n",
        "...done in 14.161759s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "=  Clean output : /data/cleaned/M30.csv\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create features, priority D  (maybe be a pain to get)\n",
      "\n",
      "# M6.\tLen(words in Evaluation page) D\n",
      "# M7.\tLen(words on Data page)  D\n",
      "# M8.\tLen(words on Main page) D\n",
      "# M25.\tLen(rows) in example submission file\n",
      "# M34.\tRatio of [16]/[4]  (participation relative to all possible participation) \u2013 Rethink this, overall don\u2019t think [4] is that useful, just points to early submitters not thoughtful submitters so expect little effect on comp staying power\n",
      "# M35.\tRatio of [30]/[4]  (interest relative to all possible participation) \u2013 Rethink this\n",
      "# M38.\tAvg or median of (Private score - Public score)  (typical overfitting observed) \u2013 Rethink this"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}